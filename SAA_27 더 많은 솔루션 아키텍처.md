### AWS의 이벤트 처리
- 첫 번째는 SQS와 Lambda를 사용하는 방법
- 이 방법은 SQS 대기열과 Lambda 함수를 사용하는 것으로 이벤트가 SQS 대기열에 삽입되고, Lambda 서비스가 SQS 대기열을 폴링
- 문제가 발생하면 해당 메시지를 다시 SQS 대기열에 입력하고, 폴링을 재시도
- 이 작업은 무한히 반복되는데 이러던 중 한 메시지에 중대한 문제가 발생하면 다섯 번의 재시도 후에는 데드 레터 대기열(DLQ)로 보내도록 SQS를 설정할 수 있음
- SQS FIFO와 Lambda를 사용하는 방법도 있음
- FIFO란 선입선출(first in, first out)이라는 의미로 도착한 순서에 따라 메시지를 처리한다는 뜻
- Lambda 함수가 대기열 메시지를 순서대로 처리를 시도하는데 순서대로 처리하기 때문에 한 메시지를 처리하지 못 하면 차단이 발생하여 처리가 끝나지 않고 결국 전체 대기열 처리가 차단
- 이 경우에도 마찬가지로 데드 레터 대기열을 구성해서 SQS 대기열에서 해당 메시지를 빼내고 함수가 계속 동작하도록 할 수 있음
- 또 다른 방법은 SNS와 Lambda를 활용하는 것으로 SNS 서비스를 사용하는 방법으로 메시지가 통과하고, 메시지는 비동기식으로 Lambda에 전송
- 이때 Lambda 함수는 재시도 행동을 달리하여 처리하지 못하는 메시지가 발생하더라도 내부적으로만 재시도를 함
- 재시도는 총 세 번까지 하며 메시지가 제대로 처리되지 않으면 해당 메시지를 제거하거나 DLQ로 보내도록 구성할 수 있지만 여기서는 Lambda 서비스 수준에서 해당 메시지를 SQS 대기열로 보내서 나중에 다시 처리할 수도 있음
- SQS를 사용할 때는 DLQ를 SQS 측에 설정하거나 Lambda 측에 설정할 수도 있음
- 팬아웃 패턴(fan out pattern)
- 팬아웃 패턴은 다중 SQS 대기열에 데이터를 전송하는 방식
-  첫 번째 패턴에서는 애플리케이션과 AWS SDK가 설치되어 있고, 세 개의 SQS 대기열에 메시지를 전송하고자 함
- 이럴 경우에는 간단히 애플리케이션을 구성할 때 먼저 메시지를 첫 번째 대기열에 보내고, 동일한 메시지를 두 번째 대기열과 세 번째 대기열에도 보냄
- 이 방식은 작동은 하지만 안정성이 높지는 않음
- 두 번째 대기열에 메시지를 전송한 다음 애플리케이션이 오류로 종료되면 세 번째 대기열은 메시지를 전달받지 못하므로 결국에 각 대기열의 콘텐츠가 달라짐
- 이 방법은 안정성도 낮고 구조도 깔끔하지 않음
- 그 대신 팬아웃 패턴을 사용하여 SQS 대기열과 애플리케이션 사이에 SNS 주제를 두면 어떻게 될까?
- 이럴 경우 SQS 대기열은 SNS 주제의 구독자가 되고 SNS 주제에 메시지를 전송할 때마다 메시지가 모든 SQS 대기열에 전달되므로 안정성이 높아짐
- 애플리케이션의 입장에서 보면 SNS 주제에 PUT 요청을 전송하면 자동으로 SNS 서비스가 해당 메시지를 SQS 대기열에 팬아웃하는 것
- 잘 작동하는 방법이고 AWS에서 자주 보이는 설계 패턴
- S3 이벤트 알림으로는 Amazon S3 버킷이 특정 이벤트에만 반응하도록 설정할 수 있어 객체 생성, 삭제 복원, 복제본 생성 시 알림을 보내도록 할 수 있고, 객체 이름별로 필터링도 가능
- 사용 사례로는 Amazon S3에 업로드된 이미지의 섬네일을 생성하는 경우가 있음
- Amazon S3 이벤트를 SNS SQS 또는 Lambda 함수로 보내는데 이때 S3 이벤트는 원하는 만큼 생성할 수 있음
- 이벤트 알림은 보통 수초 내로 전송되고 ,가끔 몇 분 이상이 소요될 수도 있음
- Amazon EventBridge를 사용하는 방법으로 Amazon S3 버킷에서 일어난 모든 이벤트 를 Amazon EventBridge로 전송하는 방식인데 규칙을 설정하여 18개 이상의 AWS 서비스로 전달할 수 있음
- 왜 EventBridge를 사용할까?
	- JSON 규칙에 고급 필터링 옵션을 사용하여 메타데이터, 객체 크기, 이름 등으로 필터링할 수 있기 때문
	- 또 여러 대상에 이벤트를 한 번에 보낼 수 있고, 예를 들어 단계 함수, Kinesis Data Stream 파이어호스 등이 대상이 될 수 있음
	- EventBridge 기능 중 아카이빙, 이벤트 재생, 그리고 안전한 이벤트 전송 등이 있는데 이 역시 활용하면 좋음
- EventBridge에 관해 설명하자면 Amazon EventBridge에서 모든 API 호출을 인터셉트하려면 CloudTrail를 통합하여 사용하면 됨
- 가령 사용자가 DynamoDB의 테이블을 삭제하고자 DeleteTable API을 호출하는 이벤트가 발생했다면 이 API 호출은 CloudTrail에 로그되며 그 외 모든 호출이 CloudTrail에 로그 됨
- 이 로그는 Amazon EventBridge의 이벤트를 트리거하므로 이를 이용해 경보를 생성하여 Amazon SNS에 전송할 수 있음
- 끝으로 API Gateway 등을 이용하는 AWS의 외부 이벤트가 있음
- API Gateway에 클라이언트가 요청을 보내면 API Gateway가 Kinesis Data Stream에 메시지를 전송
- 해당 레코드는 Kinesis Data Firehose로 이동하고 최종적으로는 Amazon S3에 저장
### AWS의 캐싱 전략
- AWS의 캐싱 전략과 캐싱 전략이 무엇을 내포하는가?
- API Gateway 앞에 CloudFront가 있다고 가정
- 애플리케이션 논리 앞에 있는 건 EC2나 Lambda가 될 수 있음
- 애플리케이션은 데이터베이스에서 데이터를 저장하고 쓰며 Redis, Memcached 혹은 DAX 등의 내부 캐시를 쓸 수도 있음
- 그럼 바로 동적 콘텐츠와 동적 라우팅이 실행됨
- 정적 콘텐츠 라우팅도 할 수 있는데 CloudFront로 가는 클라이언트나 CloudFront가 S3에서 데이터를 소싱하는 경우
- CloudFront를 살펴보면 두 개가 있는데 엣지에서 캐싱을 함
- 즉, 사용자와 최대한 가까이에서 캐싱을 한다는 뜻
- CloudFront에서 캐싱을 허용하면 캐시를 히트하는 모든 사용자들이 즉시 응답을 빠르게 얻게 된다는 것
- 엣지에 있기 때문에 백엔드에서 변화가 일어났을 수 있음
- 그리고 몇몇은 오래됐을 수도 있음
- 캐시가 최신인지 확인하려면 TTL을 사용할 수 있음
- 백엔드에서 새로운 것들을 가져올 수도 있음
- 그리고 엣지에 캐시를 얼마나 더 할 것인지와 앱 논리에 얼마나 할지 균형을 재게 됨
- API Gateway
-  API Gateway도 캐싱이 가능해서 CloudFront와 함께 사용할 필요가 없음
- API Gateway는 리전 서비스라서 API Gateway에서 캐시를 사용할 경우 캐시도 리전에 묶이게  됨
- 클라이언트와 API Gateway 사이에 네트워크 라인이 형성되어 캐시가 여기서 히트
- 앱 논리가 있는데 앱 논리는 보통 캐싱을 하지 않는데 DynamoDB가 있을 경우 Redis, Memcached DAX 등을 사용할 수 있는 캐시를 할 때 사용
- 데이터베이스를 반복적으로 히트하길 원치 않는 것
- 데이터베이스는 캐싱을 못 하니까
- 자주 발생하는 쿼리나 복잡한 쿼리가 공유 캐시에 결과가 저장되어 앱 논리에 의해 쉽게 액세스할 수 있게 하는 것
- 캐싱을 통해 절약
- 데이터베이스에 가해지는 압력을 줄이고, 읽기 용량은 늘리는 것
- Amazon S3의 데이터베이스에는 캐싱 기능이 없음
- 캐싱의 경로를 따라가보면 뒤쪽으로 갈수록 비용과 지연 시간이 늘어남
### AWS에서 IP 주소 차단
- IP 주소를 클라이언트로부터 막고 싶어 하는데 말썽이 일어나기도 하고, 애플리케이션에 액세스를 시도하기 때문에 방어선에 대해 알아야 함
- EC2 인스턴스를 사용한 간단한 솔루션 아키텍처
- VPC의 보안 그룹에서 인스턴스는 공용 IP를 써서 공용 액세스가 가능하고, 클라이언트들도 EC2 인스턴스에 이렇게 접근
- 클라이언트 차단을 원한다면 먼저 VPC 레벨에서 VPC의 네트워크 ACL방어가 첫 번째 방어선
- 이 네트워크 ACL에서는 차단 규칙을 만들 수 있는데 클라이언트 IP에 대해 아주 간단하고 빠르며 저렴하게 만들 수 있고 클라이언트를 내보내게 됨
- 그리고 EC2 인스턴스의 보안 그룹에는 차단 규칙을 만들 수 없고 허용 규칙만 가능
- 그래서 EC2 인스턴스에 액세스 가능한 권한이 부여된 클라이언트들의 서브셋만 알면 IP의 서브셋을 보안 그룹에서 지정해 EC2 인스턴스로 허용하면 됨
- 애플리케이션이 글로벌이라면 애플리케이션에 액세스하는 IP 주소를 전부 알 수도 없고 보안 그룹도 도움이 되지 않음
- 선택적으로 방화벽 소프트웨어를 EC2 인스턴스에서 실행해 클라이언트의 요청을 거절할 수 있음
- 만약 요청이 벌써 EC2 인스턴스에 도착했다면 처리가 되고 요청을 처리하는 데에 CPU 비용이 발생
- 애플리케이션 로드 밸런서
	- 이 ALB는 VPC 내에서 정의되고, EC2 인스턴스가 있는데 ALB 보안 그룹이 있고, EC2 보안 그룹이 있음
	- 로드 밸런서는 클라이언트와 EC2 사이에 위치하고, 연결 종료라는 걸 실행
	- 따라서 클라이언트는 ALB에 연결하고 , ALB에서 EC2 인스턴스로 연결을 시작하거나 종료
	- EC2 보안 그룹은 ALB의 보안 그룹을 허용하도록 구성돼야 함
	- EC2 인스턴스가 사설 IP와 클라이언트 측이 아닌 ALB로부터 오는 트래픽을 통해 사설 서브넷에 배포될 수 있기 때문
	- 보안 그룹의 관점에선 ALB 보안 그룹만 허용해서 안전해지는 것
- 보안 그룹의 ALB
	- ALB의 보안 그룹에서는 클라이언트를 허용해야 하며 아는 IP의 범위가 있어서 보안 그룹을 구성
	- 글로벌 애플리케이션일 경우 모두를 허용해야 하고, 방어선은 네트워크 ACL 레벨에 있게 됨
	- 네트워크 로드 밸런서로는 연결 종료를 하지 않음
	- 트래픽은네트워크 로드 밸런서를 거쳐가고, 그 과정에서 네트워크 로드 밸런서를 위한 보안 그룹은 없기 때문에 트래픽이 지나가게 됨
	- 그러니 IP를 새로 만드는 클라이언트는 EC2 인스턴스가 사설 IP를 사용하는 사설 서브넷에 있어도 EC2 인스턴스로 갈 수 있음
	- 모든 클라이언트의 소스 IP를 안다면 EC2의 보안 그룹에서 정의하면 되지만 클라이언트로부터 IP 주소를 하나만 차단하려면 방어를 위해 네트워크 ACL을 사용해야 한다는 것
	- **네트워크 로드 밸런서는 보안 그룹이 없고, 모든 트래픽이 지나가기 때문에 EC2 인스턴스는 엣지에서 클라이언트의 공용 IP를 감지**
	- WAF를 설치하거나 웹 애플리케이션 방화벽을 설치해 IP를 차단할 수 있음
	- WAF는 조금 비쌀 수 있는데 추가 서비스이며 방화벽 서비스이기 때문
	- WAF는 IP 주소에 대한 복잡한필터링이 가능하며 규칙을 만들어서 클라이언트로부터 동시에 많은 요청을 받지 않도록 할 수 있고, 따라서 ALB나 보안이 더 강해짐
	- WAF는 클라이언트와 ALB 사이에 있는 서비스가 아니라 ALB에 설치한 서비스로, 규칙을 많이 정의할 수 있음
	- ALB 앞에 CloudFront를 사용하면 CloudFront는 VPC 밖에 위치
	- ALB는 모든 엣지 로케이션으로부터 오는 CloudFront의 공용 IP를 허용해야 하고 온라인에 목록이 있음
	- ALB로부터 오는 것은 클라이언트 IP를 알 수 없고, CloudFront 공용 IP만 알 수 있죠 여기 네트워크 ACL은 VPC의 경계선에 있는데 클라이언트 IP를 막는 데 도움이 되지는 않음
- CloudFront로부터의 클라이언트를 막으려면 두 가지 방법이 있음
- 국가에 의해 공격당했다면 CloudFront의 지리적 제한 기능을 이용해서 CloudFront에서 클라이언트의 국가를 차단하는 방법이 있음
- 특정 IP 하나만 막고 싶다면 WAF나 웹 애플리케이션 방화벽을 사용해서 전처럼 IP 주소를 필터링하면 됨
- IP 주소를 차단하기 위한 방어선이 달라짐
### AWS의 고성능 컴퓨팅(HPC)
- 고성능 컴퓨팅 혹은 HPC
- 클라우드는 고성능 컴퓨팅을 실행하기에 최적입니다 왜 그럴까?
- 많은 리소스를 즉각적으로 생성할 수 있기 때문
- 그리고 리소스를 추가해서 결과 추출 시간을 단축할 수 있죠 또 사용량만큼만 비용을 지불하면 됨
- 작업이 끝나고 나면 전체 인프라를 제거해서 요금이 청구되지 않게 할 수 있음
- 필요에 따라 컴퓨팅을 수행하는 수많은 인스턴스를 가질 수 있고, 작업이 완료되면 사용량만큼만 비용을 지불한다는 것
- 언제 이런 HPC가 필요할까?
- 유전체학이나 컴퓨터화학 금융 위험 모델링, 기상 예측, 머신 러닝, 딥 러닝 자율 주행 등에 필요
- HPC의 작업을 돕는 AWS 서비스는 무엇이 있을까?
- 첫 번째는 데이터 관리 방식과 AWS로 데이터를 전송하는 방법에 관한 것
- AWS Direct Connect는 초당 GB의 속도로 프라이빗 보안 네트워크를 통해 클라우드로 데이터를 전송
- Snowball과 Snowmobile도 있음
- 물리적 라우팅을 통해 클라우드로 PB 단위 데이터를 옮길 때 사용하고, 주로 대용량 전송에 아주 적합
- DataSync의 경우 DataSync 에이전트를 설치해 대용량의 데이터를 전송
- 온프레미스, NFS, SMB 시스템에서 S3, EFS나 Windows용 FSx로 전송
- HPC의 컴퓨팅과 네트워킹은 어떨까요? 아주 중요한 부분
- EC2 인스턴스가 있음
- 실행하려는 작업에 따라 CPU나 GPU에 최적화된 인스턴스가 있음
- 스팟 인스턴스나 스팟 플릿(Fleet)을 사용해 비용을 크게 절약하고 수행하는 계산을 기반으로 플릿을 오토 스케일링할 수 있음
- EC2 인스턴스가 서로 통신해야 하거나 분배된 형태로 동작할 경우 클러스터 유형의 EC2 배치 그룹을 사용하면 최고의 네트워크 성능을 발휘
- 짧은 지연 시간의 10Gbps 네트워크가 될 것
- 클러스터 배치 그룹의 경우 랙(Rack)이 전부 같음
- 모두 같은 AZ에 있는 것
- EC2 인스턴스의 성능을 더 향상하는 방법은 무엇일까?
- EC2 Enhanced Networking입니다 또한 SR-IOV라고도 하는데 더 넓은 대역폭이 제공되고 더 높은 PPS 즉 초당 패킷이 높아지며 지연 시간이 짧아짐
- EC2 Enhanced Networking은 어떻게 구현할까?
	- **Elastic Network Adapter(ENA)**
	- 네트워크 속도를 100Gbps까지 올려줌
- ENA를 사용하는 게 한 가지 방법으로 대역폭과 초당 패킷을 증가시키며 지연 시간을 줄여줌
- 두 번째는 아주 복잡한 방법인데요 Intel의 82599VF라는 걸 사용해 최대 10Gbps까지 빨라집니다 오래된 ENA
- ENA와 Intel 모두 여러분의 인스턴스에서 EC2 Enhanced Networking을 이용할 수 있게 함
- Elastic Fabric Adapter(EFA)를 사용해도 됨
- HPC, 고성능 컴퓨팅을 위해 개선된 ENA인데 Linux에서만 사용 가능
- 노드 간 소통이나 밀집된 워크 로드 처리에 좋음
- 분산 계산과 같은 경우
- ENA가 사용하는 게 Message Passing Interface(MPI) 표준이기 때문
- 이 표준은 Linux OS를 우회하여 안정적이고 지연시간이 더 짧은 송신을 보장
- Linux 인스턴스가 있고, 많은 워크로드를 처리해야 할 경우에는 EFA를 사용하면 OS를 우회하여 보다 높은 네트워크 성능을 제공할 수 있음
- ENA와 EFA와 ENI 등의 차이점
- 데이터를 전송했고 또 컴퓨팅하고, 네트워크까지 구성했는데 데이터는 어떻게 저장할까?
- 몇 가지 방법이 있는데 인스턴스가 연결된 스토리지를 사용하는 방법이 있음
- EBS의 경우 io2 Block Express로 256,000IOPS까지 확장
- 인스턴스 스토어의 경우 수백만의 IOPS로 확장해요 EC2와 연결되어 하드웨어에 있고, 지연 시간이 짧지만 인스턴스가 망가지면 손상될 수 있음
- Amazon S3 등의 네트워크 스토리지를 써도 됨
- 대용량 블롭 데이터를 저장할 때 사용
- 파일 시스템 말고 큰 객체 저장을 위한 것
- EFS를 사용하면 IOPS가 파일 시스템의 전체 크기에 따라 확장
- 프로비저닝된 IOPS 모드를 써서 EFS에서 높은 IOPS를 얻기도 함
- HPC 전용 파일 시스템이 있었는데 FSx for Lustre라고 합니다 Lustre는 Linux와 Cluster용이고, HPC에 최적화되어 수백만의 IOPS를 제공하며 백엔드에서 S3로 제공
- 자동화 및 오케스트레이션은 어떨까?
- 먼저 AWS Batch를 사용하면 다중 노드 병렬 작업을 수행할 수 있고, 여러 EC2 인스턴스에 걸쳐 작업할 수 있음
- AWS Batch를 사용하면 작업 예약과 AWS Batch 서비스로 관리되어 EC2 인스턴스 실행이 쉬워wla
- 때문에 AWS Batch는 HPC에서 많이 선택하는 방법
- AWS ParallelCluster는 오픈 소스 클러스터 관리 도구로 HPC를 AWS에 배포
- 텍스트 파일로 구성해서 AWS로 배포하는 것
- VPC와 서브넷 및 클러스터 타입과 인스턴스 타입 생성을 자동화
- AWS ParallelCluster는 EFA와 함께 사용
- 클러스터 상에서 EFA를 활성화하는 매개변수가 텍스트 파일에 있기 때문입니다 따라서 네트워크 성능이 향상되고, HPC 클러스터를 구현할 수 있음
- HPC는 단일 서비스가 아니라 여러 옵션과 서비스의 결합
### EC2 인스턴스 고가용성
- 솔루션 아키텍처를 통해 EC2 인스턴스의 가용성을 높일 수 있음
- EC2 인스턴스는 기본적으로 하나의 가용 영역에서 실행
- 가용성이 그리 높지 않지만 우리가 만져서 가용성을 높일 수 있음
- 요구 사항 및 하고 싶은 일의 양에 따라 달라짐
- 웹 서버를 가동하고 있는 공용 EC2 인스턴스가 있고, 웹 서버에 액세스 한다고 가정
- EC2 인스턴스에 탄력적 IP를 연결하고, 사용자가 탄력적 IP를 통해 웹사이트에 곧장 액세스하게 해야함
- 사용자는 EC2 인스턴스에서 직접 작업할 수 있고, 우리는 웹 서버에서 결과를 받겠죠 하지만 오늘 해볼 것은 일이 잘못될 경우를 대비해 대기 인스턴스를 만들어 EC2 인스턴스의 가용성을 높이는 것
- 대비 EC2 인스턴스에 장애 조치를 취해야 함
- 뭔가 잘못됐다는 걸 알려면 모니터링이 필수
- 이미 알고 있는 이벤트에 기반해 CloudWatch Events나 경보를 만듦
- CloudWatch Events가 있다면 인스턴스가 종료되고 있는지 확인할 수 있을 것
- 웹 서버가 있다면 CPU가 100%까지 올라갈 경우를 대비해 CPU를 모니터링하는 CloudWatch 경보를 설정해야 함
- 만약 CPU가 100%에 도달한다면 EC2 인스턴스에 문제가 생긴 것이고 그에 관한 경보를 발동해야 할 것
- 인스턴스를 모니터링하는 방법은 여러 개가 있고 요구 사항에 따라 달라짐
- 그 후 경보나 CloudWatch Events에서 람다 함수를 발동할 수 있는데 람다 함수는 여러분이 원하는 작업을 할 수 있게 할 것
- 예를 들어 람다 함수는 API를 호출해 인스턴스가 실행되지 않았을 경우 실행할 수 있음
- 대기 EC2 인스턴스가 없는 경우
- 그 후 대기 인스턴스에 탄력적 IP를 연결하는 API를 호출할 수도 있음
- 이제 탄력적 IP가 연결되면 이 IP는 다른 인스턴스에서는 분리되는데 한 탄력적 IP는 한 인스턴스에만 연결될 수 있기 때문
- 다른 EC2 인스턴스는 종료되거나 사라질 것이고, 새 대기 EC2 인스턴스에는 장애 조치가 취해지는 것
- 하지만 사용자는 탄력적 IP를 통해 아키텍처와 소통하기 때문에 무슨 일이 일어나는지는 알 수 없습니다 다 백엔드에서 진행됨
- 고가용성 EC2 인스턴스를 만드는 방법 중 하나임
- 다른 방법은 오토 스케일링 그룹을 이용하는 것
- 두 가용 영역에 오토 스케일링 그룹(ASG)이 있다고 가정
- 사용자가 탄력적 IP를 통해 애플리케이션과 소통하게 만들어 조금 더 단순화하는 것
- ASG를 어떻게 구성해야 할까?
- 인스턴스의 최솟값과 최댓값을 1로 설정하고 적정 값도 1로 설정해 두 개의 가용 영역에 지정하는 것
- EC2 인스턴스를 하나만 가져오는 건데 그 인스턴스는 첫 번째 가용 영역에 들어가게 됨
- EC2 인스턴스의 사용자 데이터가 나타나게 되면 이 탄력적 IP 주소를 태그에 기반해 연결할 것
- 사용자 데이터가 API 호출을 발행하고 탄력적 IP가 공용 EC2 인스턴스에 연결되는 것
- 사용자가 웹 서버와 소통할 수 있게 됨
- 인스턴스가 종료될 경우 ASG가 뭘 하는지 알아보죠 ASG는 첫 인스턴스를 종료하고 다른 가용 영역에 대체 EC2를 생성
- 첫 번째 인스턴스가 종료되고 두 번째 인스턴스가 EC2 사용자 데이터 스크립트를 실행하고 탄력적 IP를 연결
- 사실상 장애 조치가 취해지는 거죠 이 경우에는 CloudWatch 경보나 Events가 필요 없음
- 한 인스턴스가 종료되는 것을 ASG가 보자마자 아까 설정한 대로 다른 가용 영역에 새 EC2 인스턴스를 생성할 것
- 최소, 최대, 적정 값을 1로 설정한 이유는 ASG 전체에서 동시에 여러 개의 인스턴스를 실행할 수 없기 때문
-  EC2 인스턴스가 이 탄력적 IP 주소를 연결하기 위해 API를 직접적으로 호출할 때 해당 인스턴스가 탄력적 IP 주소를 연결하기 위해 API를 호출할 수 있는 인스턴스 역할이 있는지 확인해야 함
- EC2 사용자 데이터를 이용해 탄력적 IP 주소를 연결하고 API 호출이 성공할 수 있도록 하기위햐서는?
- 이 패턴은 다른 영역으로도 확장 가능한데 예를 들어, EC2 인스턴스를 상태 유지하게 하고 EBS 볼륨을 줄 수 있음
- ASG와 두 가용 영역 공용 EC2 인스턴스와 탄력적 IP가 있음
- EC2 인스턴스에 EBS 볼륨까지 연결할 것
- EC2 인스턴스가 데이터베이스라고 가정 이 데이터베이스를 고가용성으로 만든다고 가정
- 모든 데이터가 EBS 볼륨에 있고 EBS 볼륨은 특정 가용 영역에만 고정되어 있음
- EC2 인스턴스가 종료된다고 가정
- 인스턴스가 종료될 경우 ASG는 수명 주기 후크를 사용
- 수명 주기 후크 덕에 EBS 볼륨에서 스냅샷을 얻을 수 있는 스크립트를 생성할 수 있음
- EC2 인스턴스가 종료되자마자 스냅샷이 발동되기 때문에 EBS 볼륨에 문제가 생겼다는 것을 알 수 있음
- EBS 스냅샷을 올바르게 태그하면 ASG는 대체 EC2 인스턴스를 실행할 것
- 실행 이벤트에 수명 주기 후크를 생성하도록 ASG를 올바르게 구성함으로써 이 EBS 스냅샷에 기반해 올바른 가용 영역에 EBS 볼륨을 생성할 수 있음
- 대체 EC2 인스턴스에 이걸 연결하면 EC2 사용자는 이것만 확인하고, 탄력적 IP를 직접적으로 연결하면 됨
- API 호출이 제대로 됐는지 확인해야 하니 EC2 인스턴스 역할이 있어야 함
- EBS 볼륨이 스냅샷을 만들고 그 스냅샷에서 다른 가용 영역으로 복구되는지 확인하기 위해 EC2 사용자 데이터 및 수명 주기 후크를 이용했는데 EBS 볼륨으로 고가용성 EC2 인스턴스를 만드는 법
###  기타 서비스
### CloudFormation - 소개
- CloudFormation은 AWS에서 매우 중요한 기술인데요, 리소스에 대해 인프라의 윤곽을 구분짓는 선언적 방법이기 때문입니다, 거의 대부분의 리소스가 지원됨
- 첫 번째는 모든 인프라가 코드라는 것이 장점
- 수동으로 리소스를 만들 필요가 없어 컨트롤이 편함
- AWS 클라우드의 작동 방식을 변경할 때마다 코드 리뷰를 통해 검토합니다, 클라우드에서 작업하기 매우 좋은 방법
- 비용적인 면에서 이익, 왜냐하면 스택 내의 각 리소스는 스택 내에서 만들어진 다른 리소스들과 비슷하게 태그되기 때문
- CloudFormation 템플릿을 사용하여 리소스 비용을 쉽게 예측할 수도 있음
- 마지막으로 CloudFormation으로 절약 전략을 세울 수도 있음
- 예를 들어 어떤 환경에서 오후 5시에 자동으로 모든 템플릿을 삭제하도록 할 수 있음
- 템플릿과 연결된 모든 리소스를 삭제한 다음, 오전 9시 또는 안전하게 오전 8시에 다시 생성하도록 하는 것
- 오후 5시와 오전 8시 사이에는 리소스가 없기 때문에 비용을 절감할 수 있음
- CloudFormation을 통해 리소스를 쉽게 만들 수 있음
- 생산성이 높음
- 선언적 프로그래밍도 가능, 따라서 EC2 인스턴스에서 Dynamo DB 테이블을 먼저 만들어야 하는지, 한 번에 같이 해야 하는지 알 필요가 없음
- CloudFormation을 사용하면, 하나하나 다 만들지 않아도 됨
- 웹에 존재하는 기존 템플릿을 활용할 수 있음
- CloudFormation은 AWS에서 코드형 인프라의 기반
- CloudFormation을 시각적으로 볼 수 있어, 만들어진 걸 다이어그램으로 볼 수 있음
###  Amazon SES
- 단순 이메일 서비스
- 완전 관리형 서비스
- 이메일을 전 세계로 대규모로 안전하게 보낼 수 있는 서비스
- 즉, 여러분의 애플리케이션이 SES API 또는 SMTP 서버를 사용하면 Amazon SES가 사용자들에게 대량으로 이메일을 보냄
- 아웃바운드뿐 아니라 인바운드 이메일도 허용하기 때문에 답장을 주고받을 수 있음
- 이메일을 열었는지 여부를 알려주는 평판 대시보드와 성과 인사이트, 스팸 방지 피드백을 제공
- 이메일 전송에 대한 최신 보안 기준을 지원
- DKIM과 SPF 기능
- 배포도 유연하게 됨
- 공유 IP, 전용 IP, 또는 여러분의 고객 소유 IP들이 있음
- 정 IP 주소에서 이메일을 보내는 것
- 그리고 API는 콘솔에서 액세스 가능
- 특정 AWS API 또는 SMTP 프로토콜에서
- Amazon SES의 사용 사례는 이메일 트랜잭션 마케팅 이메일 대량 이메일 커뮤니케이션을 들 수 있음
### Amazon Pinpoint
- Amazon Pinpoint는 확장 가능한 양방향 인바운드 및 아웃바운드 마케팅 커뮤니케이션 서비스
- Pinpoint를 통해 이메일, SMS, 푸시 알림, 음성, 인앱 메시지를 보냄
- SMS
- Amazon Pinpoint를 통해 고객에게 SMS를 보낼 수 있음
- 고객에게 적합한 콘텐츠로 메시지를 세분화하고 개인화할 수 있습니다, 그룹이나 세그먼트 등을 만들 수 있음
- Pinpoint의 사용 사례는 마케팅 이메일을 대량으로 보내거나 트랜잭션 SMS 메시지를 전송하여 캠페인을 실행하는 것
- 그리고 누군가 응답하거나 성공하면 TEXT_SUCCESS, TEXT_DELIVERED, REPLIED와 같은 모든 이벤트가 Amazon SNS, Kinesis Data Firehose, CloudWatch Logs로 전달됩니다, 즉, Amazon Pinpoint로 모든 종류의 자동화를 쉽게 구축할 수 있음
- Pinpoint와 Amazon SNS나 Amazon SES의 차이점?
- SNS 또는 SES에서는 여러분이 각 메시지의 대상, 내용, 전달 일정을 관리해야 함
- 애플리케이션이 해야 하는 일이죠, 많은 작업이 필요하며 확장이 되지 않을 수도 있음
- Amazon Pinpoint에서는 여러분이 직접 메시지 템플릿, 전달 일정 , 대상 세그먼트, 전체 캠페인 등을 만들지 않고 Pinpoint 서비스로 관리할 수 있음
- 완전한 마케팅 커뮤니케이션 서비스를 하고 싶다면, SAS 및 SES의 차세대 제품인 Pinpoint가 적합
### SSM Session Manager
- 사례 분석에서는 시스템 관리자의 SSM 세션 관리자 기능
- 이를 통해 EC2 인스턴스와 온프레미스 서버에서 보안 셸을 시작할 수 있음
- SSH 액세스, 배스천 호스트, SSH 키가 필요 없음
-  EC2 인스턴스의 포트 22는 닫힐 것
- EC2 인스턴스에 보안 셸을 설정하기 위해 SSH를 실행할 필요가 없으니까
- 보안이 더 낫다는 뜻
- EC2 인스턴스에는 SSM 에이전트가 있고, 그 에이전트는 세션 관리자 서비스에 연결
- 사용자는 세션 관리자 서비스를 통해 EC2 인스턴스에 액세스할 수 있음
- Linux, MacOS, Windows를 지원하며, 로그 데이터를 Amazon S3 또는  CloudWatch Logs로 보낼 수 있습니다, 매우 안전
-  EC2 인스턴스를 시작해야 함
- 인스턴스를 시작하고 아래로 스크롤
- Amazon Linux2 AMI를 선택하고요, t2.micro를 선택
- 키 페어는 사용하지 않고요, SSH 트래픽을 비활성화, 그러면 EC2 인스턴스는 아무것도 허용하지 않는 보안 그룹을 갖게 됨
- HTTP, HTTPS, SSH가 허용되지 않지만, SSM 세션 관리자를 셸로 사용할 수 있음
- IAM 인스턴스 프로필을 내 인스턴스에 결합시켜 그것이 SSM 서비스와 대화할 수 있도록 하는 것
- Create new IAM profile에서  SSM로 필터링해AmazonSSMManagedInstanceCore를 선택  후DemoEC2RoleForSSM이라고 할게요, 이렇게 하면 EC2가 이 정책을 사용하여 SSM 서비스 사용 가능
- Fleet Manager에는 SSM에 등록된 모든 EC2 인스턴스가 표시
- 관리 노드라
- SSM 에이전트가 온라인 상태인 걸 볼 수 있죠, 플랫폼, 운영 체제 Amazon Linux 2 SSM 에이전트 버전, 그리고 EC2 인스턴스로 연결되는 링크도 있음
- 인스턴스가 Fleet Manager에 나타나면, 이에 대한 보안 셸을 실행할 준비가 됐다는 뜻
- 세션 관리자는 Linux 인스턴스와 Windows 인스턴스에 액세스하는 방법
- 보안 그룹 아래에 제 EC2 인스턴스가 있고,  인바운드 규칙이 없음
- 보안 셸이 있음
- SSH 액세스가 필요하지 않았죠, ping google.com을 하면 당연히 잘 작동
- 호스트 이름을 알기 위해 hostname을 하면 ip는 172.31.1.148인데 Networking으로 가서 제 인스턴스의 개인 IP 주소를 보면 정확히 일치
- SSM 보안 셸을 사용하면 AWS에서 직접 보안 셸을 사용할 수 있음
- SSH 보안 키나 SSH 액세스가 없이
- EC2 인스턴스에 액세스하는 데는 세 가지 방법
- 첫 번째는 포트 22를 연 다음 SSH 키와 터미널을 사용하여 SSH 명령을 수행하는 것
- 두 번째는 EC2 Instance Connect를 사용하는 것
- SSH 키는 필요없어요, 왜냐하면 필요한 경우엔 Amazon EC2에 일시적으로 업로드 되기 때문
- EC2 Instance Connect를 사용하여 EC2 인스턴스에 액세스하려면 여전히 포트 22를 열어야 함
- 세 번째 방법을 같이 살펴봤죠, 세션 관리자
- Amazon EC2에 인스턴스가 있는지 확인하고, 이 EC2 인스턴스가 IAM 역할이 있는지 반드시 확인하고 IAM 역할은 Security에서 볼 수 있죠, IAM 역할은 EC2 인스턴스에서 세션 관리자로 액세스를 허용하여 이를 통해 보안 셸을 실행할 수 있음
- 세션 기록이 로그로 저장
### SSM 기타 서비스
- 첫 번째는 명령을 실행
- 시스템 관리자 서비스에 등록된 EC2 인스턴스 또는 온프레미스 서버들에서
- 왜냐하면 에이전트가 거기서 실행되고 있으니까
- 따라서 이 명령들을 실행할 때는 SSH가 필요하지 않음
- 세션 관리자에서 본 것과 같은 메커니즘을 사용
- 실행 명령으로 실행된 명령의 결과는 모두 S3 또는 CloudWatch 로그로 보내짐
- 실패가 일어나면 SNS로 전송됨
- 따라서 진행 중, 성공, 실패 등 이런 모든 업데이트를 SNS로 보낼 수 있음
- 보안을 위해 IAM과 완벽하게 통합
- 그리고 CloudTrail에서 누가 어떤 명령을 실행하는지 확인할 수 있음
- EventBridge로 실행 명령을 직접 실행할 수도 있음
- 즉, EC2 인스턴스 또는 온프레미스 서버가 있고, SSM 에이전트로 관리를 통해 매우 간단히 명령을 실행할 수 있음
- 세션 관리자의 명령 실행 기능을 사용해서
- 출력 결과는 Amazon S3 또는 CloudWatch 로그로 전송할 수 있음
- 모든 상태 알림은 Amazon SNS로 전송
- 사용자인 우리가 트리거하거나 EventBridge로 자동으로 트리거할 수도 있음
- 다른 하나는 패치 관리자라고 하는데 이름에서 알 수 있듯 매우 간단
- 인스턴스 관리 과정 패칭을 자동화하는 데 사용
- 즉, 운영 체제 및 애플리케이션 업데이트 그리고 보안 업데이트를 적용하는 데 사용
- 물론 EC2 인스턴스와 온프레미스 서버도 지원
- Linux, Mac, Windows를 지원
- 유지 관리 기간이라는 것을 사용하여 패치 일정을 잡을 수도 있음
- 인스턴스를 패치할 준비를 하는 곳
- 패치 관리자 내에서도 인스턴스를 스캔하여 패치 규정 준수 보고서를 생성할 수 있음
- 모든 인스턴스가 올바르게 패치되었는지 확인하고 패치가 누락된 사람이나 경우가 있는지 찾을 수 있음
- 즉, 콘솔이나 SDK 또는 유지 관리 기간에서 패치 관리자를 호출할 수 있음
- AWS-RunBatchBaseline 실행 명령
- 모든 EC2 인스턴스를 패치
- 패치 관리자 내에서 보고서를 찾을 수 있음
- 유지 관리 기간
- 인스턴스에서 작업을 수행할 일정을 정의하는 데 사용
- 예를 들어 OS 패치, 드라이버 업데이트 및 소프트웨어 설치 또는 원하는 작업을 수행하기 위해 유지 관리 기간을 정의할 수 있음
- 유지 관리 기간을 정의할 때는 일정을 넣어야 함
- 어느 인스턴스에 이 유지 관리 기간을 적용할지
- 마지막으로 이 유지 관리 기간 동안 실행될 작업을 정해야 함
- 명령 실행이든 EC2 인스턴스 업데이트든 패치 작업이든 간에요 자유롭게 설정하면 됨
- 다음으로 자동화
- 자동화는 EC2 인스턴스 또는 기타 AWS 리소스에서의 명령 유지 관리 및 배포 작업을 단순화하는 데 사용
- 예를 들어, 자동화를 사용하면 인스턴스들을 한 번에 다시 시작할 수 있음
- AMI를 생성하거나 EBS 스냅샷을 생성하는 등의 작업을 할 수 있음
- 자동화(Automation) 런북도 있음
- EC2 인스턴스 또는 AWS 리소스에 동일한 문서로 표시된 미리 정의된 작업
- 런북은 SSM 자동화에서 사용
- EC2 인스턴스에서 특정 작업을 실행합니다 예를 들어, 전부 재시작 등의 작업
- 또는 AWS 리소스에서 작업을 실행할 때 사용
- 예를 들어, 모든 RDS 데이터베이스의 스냅샷을 생성할 수 있음
- 따라서 콘솔, SDK 및 CLI, Amazon EventBridge, 유지 관리 기간 또는 AWS config를 사용하여 트리거될 수 있습니다 따라서 통합할 수 있음
- 예를 들어 config에서 리소스가 준수되지 않은 것을 알게 된 경우 SSM 자동화를 실행하기 위해 자동으로 수정 조치를 취할 수 있음
- 비준수 리소스를 수정
### AWS 비용 탐색기
- 비용 탐색기(Cost Explorer)라는 청구 서비스
- AWS 비용 및 시간에 따른 사용량을 시각화하고 이해하며 관리하는 데 사용
- 사용자 정의 보고서를 생성해서 비용과 사용량 데이터를 분석할 수 있음
- 전체적인 데이터를 분석할 수 있는데 예를 들어 전체 계정 간 총비용 및 사용량 등
- 청구서 요금을 낮추기 위한 최적의 절감형 플랜을 선택할 수 있기 때문
- 향후 12개월까지의 사용량을 예측할 수 있음
- 이전 사용량을 기반으로 하며 비용 계획에 큰 도움
- 비용 탐색기의 예시를 보면 AWS 서비스의 월별 비용이 있음
- 인스턴스 유형에 따라 일부는 다른 것보다 더 비쌀 수 있고 따라서 비용을 최적화하며 인스턴스가 올바로 사용되는지 최대한으로 사용 중인지 크기는 적절한지 등의 질문을 하게 됨
- 시간별 리소스 레벨
- EC2 인스턴스의 리소스 레벨 정보를 얻는데 시간에 따른 비용이 표시
- 즉 시간별로 확인할 수 있어서 청구서를 분석하고 이해할 수 있음
- 비용 탐색기로 절감형 플랜을 찾을 수도 있음
- 절감형 플랜은 예약 인스턴스의 대안인데 비용 탐색기를 사용하면 여기 보이는 팝업에서처럼 사용량에 따라 어떤 절감형 플랜을 선택할 수 있는지 알려줌
- 과거에 지출했던 비용을 기반으로 예측을 할 수 있는데 청구서 비용에 대한 예측에 확신을 가질 수도 있음
### AWS Batch
- Batch는 완전 관리형 배치 처리 서비스로, 어떤 규모의 배치라도 처리할 수 있음
- Batch 서비스를 사용하면 AWS에서 수십만 개의 컴퓨팅 배치 작업을 매우 쉽고 효율적으로 실행할 수 있음
- 배치 작업은 시작과 끝이 있는 작업입니다, 연속적인 결코 끝나지 않는 스트리밍 작업은, 항상 실행 중
- 배치 작업은 반대입니다, 배치 작업은 예를 들어 오전 1시에 시작하여 오전 3시에 종료
- 배치 작업에는 시작 시점이 있음
- 따라서 Batch 서비스는 동적으로 EC2 인스턴스 또는 스팟 인스턴스를 시작
- 배치 작업을 로드하기 위해서
- Batch는 배치 대기열을 처리할 수 있도록, 적절한 양의 컴퓨팅 및 메모리를 프로비저닝
- 배치 작업을 배치 대기열에 올리거나 예약하기만 하면, Batch 서비스가 나머지 작업을 수행
- 도커 이미지와 ECS 서비스에서 실행되는 작업 정의
- 즉, ECS에서 실행될 수 있는 것이라면 배치에서도 실행될 수 있다는 뜻
- Batch를 사용하여 배치 작업을 실행하면 매우 좋음
- 왜냐하면 작업에 필요한 EC2 인스턴스 또는 스팟 인스턴스의 적절한 수를 자동으로 조정해주기 때문
- 예를 들어 사용자가 Amazon S3에 넣은 이미지를 배치 방식으로 처리하고 싶다고 가정
- 이미지가 Amazon S3에 입력되면 배치 작업이 트리거
- Batch는 자동으로 EC2 인스턴스 또는 스팟 인스턴스로 구성된 ECS 클러스터를 갖게 되며 Batch는 배치 대기열에 있는 배치 작업을 수행할 수 있는 적절한 양의 인스턴스가 있는지 확인
- 그리고 인스턴스는 작업을 수행할 Docker 이미지를 실행
- 작업은 처리된 객체를 삽입하는 일이거나 이미지를 다른 Amazon S3 버킷으로 넣는 필터일 수도 있음
- Batch와 Lambda의 차이점이 궁금하실 텐데요, 둘은 비슷
- Lambda에는 15분의 시간 제한이 있습니다, 그리고 프로그래밍 언어 몇 개로만 액세스할 수 있고
- 작업을 실행하는 임시 디스크 공간이 제한되어 있습니다, 서버리스
- Batch는 매우 다름
- Batch는 EC2 인스턴스에 의존하기 때문에 시간 제한이 없음
- 도커 이미지로 패키징하는 한, 런타임의 길이는 상관없음
- 스토리지는, EC2 인스턴스와 같이 제공되는 스토리지를 사용
- EBS 볼륨이 될 수도 있고 디스크 공간을 위한 EC2 인스턴스 스토어일 수도 있음
- Lambda 함수보다 훨씬 더 많을 수 있음
- 마지막으로 Batch는 서버리스 서비스가 아니라 관리형 서비스이지만 만들어지는 실제 EC2 인스턴스에 의존
### Amazon AppFlow
- AppFlow는 SaaS 애플리케이션 및 AWS 사이에 데이터를 전송할 수 있는 완전 관리형 통합 서비스
- 데이터 소스는 예를 들어 Salesforce, SAP, Zendesk, Slack, ServiceNow 등
- Salesforce는 시험에 나올 수 있는 항목, Amazon S3, Amazon Redshift 또는 Snowflake나 Salesforce와 같이 AWS가 아닌 것으로도 데이터를 보낼 수 있음
- 일정에 따라, 또는 특정 이벤트에 대한 응답으로, 또는 주문형으로 통합되도록 정의할 수 있음
- AppFlow 내에서 필터링, 유효성 검사와 같은 데이터 변환도 할 수 있고요, 데이터는 공용 인터넷을 통해 암호화되거나, PrivateLink를 사용하여 비공개로 전송할 수 있음
- AppFlow을 사용하면 통합을 만드는 데 시간을 쓰지 않아도 됨
- API를 활용하여 여러분의 계정 내에서 바로 데이터를 사용할 수 있음
- AppFlow 인터페이스에는 Sources가 있어요, 다양한 소스들이 있는데 Salesforce 등 앞에서 말씀드렸던 것들이 중요
- AppFlow을 사용하면 이 데이터를 다양한 곳으로 보낼 수 있음, Redshift나 S3 등
### AWS 증폭
- 웹 및 모바일 애플리케이션 개발 도구
- Amplify를 사용하면 AWS의 많은 스택을 한 곳에 통합해서 웹 및 모바일 애플리케이션을빌드할 수 있음
- 백엔드를 만든다고 가정
- Amplify CLI를 사용해서 Amplify 백엔드를 만들 것
- 이 백엔드는 우리가 아는 많은 AWS 리소스를 내부적으로 사용할 것
- 데이터 저장을 위해 Amazon S3를 사용하고 신원 증명을 위해 Amazon Cognito를 사용하고요, API에 AppSync를 사용하고 API Gateway도 사용
- 머신러닝을 위해 SageMaker도 사용
- 텍스트 감지를 위해 Lex를, 서비스형 함수를 위해 Lambda를, 데이터를 위해 DynamoDB를 사용해요, 그것 말고도 많아요, 그럼 Amplify 덕분에 한 곳에서 인증, 스토리지 REST API나 GraphQL API 등의 API CI/CD, PubSub, Analytics, AI/ML 예측, 모니터링 등을 설정할 수 있음
- 출처는 는 모든 곳이 될 수 있어요, GitHub, AWS CodeCommit, Bitbucket, GitLab 등이 있고 직접 코드를 업로드할 수도 있음
- 이 모든 백엔드 서비스를 Amplify 안에서 직접 통합
- Amplify 프런트엔드 라이브러리를 추가해서 여러분의 Amplify 백엔드에 연결하고 웹이나 모바일 애플리케이션용으로 아주 많은 프런트엔드 라이브러리가 있고요, 프레임워크도 아주 많음
- 그리고 마지막으로, 준비를 마쳤으면 Amplify 콘솔을 이용해서 Amplify 자체에 배포하거나 Amazon CloudFront에 배포해서 여러분의 웹 또는 모바일 애플리케이션을 제공
- Amplify를 웹 및 모바일 애플리케이션을 위한 Elastic Beanstalk
- 하나의 장소로 통합해서 개발자가 웹과 모바일 애플리케이션을 만들기 위한 원스톱 쇼핑몰이 됨
