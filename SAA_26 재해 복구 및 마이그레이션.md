### AWS의 재해 복구
- 온프레미스 간 재해 복구(on-premise DR)
	- 캘리포니아에 첫 번째 데이터 센터가 존재, 나머지 하나는 시애틀에 존재한다고 가정
	- 비용이 높음
- 하이브리드 복구(hybrid DR)
	- 또는 클라우드를 사용해 온프레미스를 기본 데이터 센터로 두고 재해 발생 시 클라우드를 사용해 복구하는 방법
- 완전 클라우드 유형
	- 모두 클라우드에 있어 Cloud 리전 A에서 B로 재해 복구 수행
- `RPO`: 복구 시점 목표
	- 얼마나 자주 백업을 실행할지, 시간 상 어느정도 과거로 되돌릴 수 있는가를 결정
	- 재해가 발생하면 RPO와 재해 발생 시점 사이에 **데이터 손실이 발생**
		- 데이터를 매시간 백업할 경우 재해가 발생하면 한 시간 전으로 돌릴 수 있으므로 그 사이 데이터가 유실됨
	- <u>데이터 손실을 얼만큼 감수할지 결정하는 것</u>
- `RTO`: 복구 시간 목표
	- 재배 발생 후 복구할 때 사용
	- 재해 발생 시점과 RTO의 시간 차는 어플리케이션 다운타임
	- RTO가 빠르면 다운타임이 줄어듦
- RPO와 RTO 최적화는 시간 간격이 짧을 수록 비용이 높아짐
- 재해 복구 전략
	- 백업과 복구(backup and restore)
		- RTO가 작고 RPO가 큼
		- 기업 데이터 센터와 Cloud 및 S3 버킷이 있다고 가정하면 시간에 따라 데이터를 백업하고 싶을 경우 Storage Gateway를 사용할 수 있음
		- 수명 주기 정책을 만들어 비용 최적화 목적으로 Glacier에 데이터를 입력하거나 Snowball을 이용해 일주일에 한 번식 많은 양의 데이터를 Glacier에 전송할 수 있음
		- Snowball을 사용하면 RPO는 대략 일주일정도 걸리는데 Snowball 장치로 일주일에 한 번만 보내 한 주 치 데이터를 잃게 됨
		- Cloud 사용 경우 EBS 볼륨과 RedShift RDS를 사용해 정기적으로 스냅샷을 예약하고 백업하면 스냅샷 간격에 따라 RPO가 달라짐
		- AMI를 사용해 모든 데이터를 복원할 수 있음
		- 데이터 복구 시간은 오래 걸려 RTO는 커지지만 가격이 저렴하고 인프라를 관리할 필요 없음
		- 백업 복구는 쉽고 비용은 저렴하지만 RPO와 RTO가 높음
	- Pilot Light
		- RTO가 빠름
		- 어플리케이션 축소 버전이 클라우드에서 항상 실행되고 크리티컬 코어가 됨
		- 백업 및 복구와 비슷하지만 크리티컬 시스템이 항상 작동해 복구 시 속도가 더 빠름
		- 데이터센터와 Cloud가 있고 크리티컬 DB에서 RDS로 데이터를 계속 복제한다면 언제든 실행 가능한 RDS DB를 확보하게되지만 EC2 인스턴스는 크리티컬 시스템이 아님
		- 따라서 작동하지 않고 잇다가 재해 발생 시 Route 53이 데이터 센터 서버에 장애 조치를 허용해 클라우드에 EC2 인스턴스를 재생산하고 실행시킴 이때 RDS DB는 이미 준비된 상태라 RPO와 RTO가 낮아짐
		- 비용 관리가 필요하고 RDS가 실행중이나 RDS DB만 작동하고 나머지는 작동하지 않아 재해 복구 시 EC2 인스턴스만 불러옴
		- 크리티컬 코어 보조에만 사용
	- Warm Standby(웜 대기)
		- RTO가 빠름
		- 시스템 전체를 실행하되 최소한의 규모로 가동해서 대기하는 방법 -> 재해 발생 시 프로덕션 로드로 확장 가능
		- 데이터 센터가 있고 역방향 프록시와 어플리케이션 서버, 마스터 DB를 포함한 Route 53이 DNS를 기업 데이터 센터로 가르키고 있을 때 데이터 복제가 이루어져 EC2 ASG가 최소 용량으로 가동하며 기업 데이터 센터와 소통하고 ELB가 준비됨
		- 재해 발생 시 Route 53을 이용해 ELB로 장애 조치해서 어플리케이션이 데이터를 가져오는 곳을 대기 중인 클라우드로 변경 가능
		- ELB와 EC2 ASG가 동시 실행 되어 비용이 더 들지만 RPO와 RTO가 줄어듦
	- Hot Site / Multi Site Approach(핫 사이트 / 다중 사이트 접근)
		- RTO가 매우 빠르지만 비용이 높음
		- 온프레미스에서 두개의 완전한 프로덕션 스케일을 가지고 있음
		- 온프레미스 데이터 센터 완전 프로덕션 스케일과 데이터 복제를 진행하는 동시에 AWS 데이터 센터 완전 프로덕션 스케일이 가능
		- 이미 실행중인 핫 사이트가 있어 Route 53이 기업 데이터 센터와 AWS Cloud에 요청을 라우팅할 수 있는데 `active-active 유형 설정`
	- 모두 클라우드로 실행
		- 다중 리전이고 클라우드 내에 있으므로 오로라 사용도 가능
		- 리전에 마스터 DB가 있고, Slave로 다른 리전에 복제된 오로라 글로벌 DB도 있음
		- 장애 조치 시 완전 프로덕션 스케일이 다른 리전에서 가능
- 백업에는 EBS 스냅샷과 RDS로 자동화된 스냅샷과 백업 등을 사용하고 S3, S3 IA, Glacier 등에 스냅샷을 규칙적으로 푸시 가능하며 수명 주기 정책도 실행 가능
- 백업이 다른 리전에 있길 원한다면 리전 간 복제도 가능
- 온프레미스에서 클라우드로 데이터 공유 시 Snowball과 Storage Gateway가 유용
- 고가용성을 위해 Route 53을 사용해 DNS를 다른 리전으로 옮길 수 있음
- RDS 다중 AZ, ElastiCache, 다중 AZ EFS, S3등을 사용하면 가용성이 높아짐
- 네트워크 고가용성으론 기업 데이터 센터에서 AWS로 연결할 때 Direct Connect를 실행할 수 있고, 만약 연결이 끊기면 Site-to-Site VPN을 네트워크 복구 옵션으로 사용 가능
- RDS 리전 간 복제, 오로라 글로벌 DB로 복제 가능하고 온프레미스 DB를 RDS로 복제할 때 DB 복제 소프트웨어를 사용하거나 Storage Gateway도 있음
- CloudFormation과 Elastic Beanstalk로 자동화된 재해 복구도 가능
- ClousWatch를 사용해 경보가 실패하면 EC2 인스턴스를 복구하거나 다시 시작할 수 있음
- Lambda는 사용자 맞춤 자동화에 유용해 인프라 전체를 자동화할 때 효과적
- Chaos 테스트는 재해를 만들어 복구 테스트
	- 넷플릭스는 모든 걸 AWS에서 실행하고 Simian Army를 만들어 EC2 인스턴스를 무작위로 종료시키고, 인프라가 무시하도록 카오스 몽키를 실행해 무작위로 종료 시킴
### 데이터베이스 마이그레이션 서비스(DMS)
- 데이터베이스 시스템을 온프레미스 시스템에서 AWS Cloud로 마이그레이션하려 한다고 가정 -> 마이그레이션 서비스를 의미하는 DMS를 필요
- 데이터베이스를 온프레미스에서 AWS로 마이그레이션하게 해주는 빠르고 안전한 데이터베이스 서비스
- 복원력이 있고 자가 치유가 가능, 마이그레이션을 해도 소스 데이터베이스를 계속 사용할 수 있고, 다양한 유형의 엔진을 지원
	- 예를 들어 Oracle에서 Oracle로 혹은 Postgre에서 Postgre로 동종 마이그레인션도 되고, Microsoft SQL Server에서 Aurora까지 이종 마이그레이션도 지원
	- CDC, 즉 Change Data Capture를 이용한 지속적 데이터 복제도 가능
- DMS를 사용하려면 EC2 인스턴스를 만들어야 하고, 그 EC2 인스턴스가 대신 복제 작업을 수행함
- 소스 데이터베이스가 온프레미스에 있고 DMS 소프트웨어를 가진 EC2 인스턴스를 실행, 그  소스 데이터베이스에서 데이터를 계속적으로 가져오고 그걸 타깃 데이터베이스에 넣게 됨
- **소스**는 온프레미스 데이터베이스나 Oracle, Microsoft SQL Server, MySQL, MariaDB, PostgreSQL, MongoDB, SAP, DB2 같은 EC2 인스턴스 기반 데이터베이스 또는 Azure SQL Database 같은 Azure 데이터베이스, Aurora 등 모든 Amazon RDS, Amazon S3와 DocumentDB도 가능
- **타깃**에도 다양한 선택지 존재
- 온프레미스와 EC2 인스턴스 데이터베이스, Oracle, Microsoft SQL Server, MySQL, MariaDB, PostgreSQL, SAP 등이 될 수 있고, Amazon RDS의 모든 데이터베이스가 될 수도 있음
- Redshift, DynamoDB, Amazon S3도 가능하고, OpenSearch Service, Kinesis Data Streams, Apache Kafka, DocumentDB, Amazon Neptune, Redis, Babelfish도 가능
- <u>DMS를 이용하면 예를 들어 온프레미스 데이터베이스를 AWS에서 제공하는 거의 모든 데이터베이스에 손쉽게 넣고, 내보내고, 마이그레이션할 수 있음</u>
- 소스 데이터베이스와 타깃 데이터베이스의 엔진이 다른 경우에는 어떻게 될까?
	- `AWS SCT`를 사용해야 함, SCT는 스키마 변환 도구를 의미, 그게 데이터베이스 스키마를 엔진 간에 변환
	- `OLTP`를 사용한다면 SQL Server나 Oracle에서 MySQL, PostgreSQL 또는 Aurora로 마이그레이션을 할 수 있음
	- Teradata나 Oracle에서 Amazon Redshift로처럼 분석을 목적으로 변환할 수도 있음
	- 소스 데이터베이스의 엔진이 타깃 데이터베이스와 다르고 중간에는 DMS가 있음, 하지만 스키마 변환 도구 즉 SCT도 실행되고 있음
	- **동일한 데이터베이스 엔진 간에 마이그레이션을 할 때는 SCT를 사용할 필요가 없음**
	- 온프레미스 PostgreSQL에서 RDS PostgreSQL로 마이그레이션한다면 데이터베이스 엔진이 PostgreSQL로 동일하기 때문에 그 경우에는 SCT를 사용하지 않음
	- Oracle에서 Postgre로 마이그레이션할 때는 SCT를 사용해야 함
	- 데이터베이스 엔진은 PostgreSQL이지만 RDS는 그 데이터베이스 엔진을 실행하기 위해 사용하는 플랫폼
- DMS에 지속적 복제를 어떻게 설정할까?
	- 예를 들어 Oracle DB 같은 기업 데이터 센터를 소스가 갖고 있음, 그리고 MySQL DB를 위한 Amazon RDS 데이터베이스를 타깃으로 갖고 있음 두 가지 다른 유형의 데이터베이스를 갖고 있음
	- AWS SCT를 설치하여 서버를 설정하고, 그걸 온프레미스에서 설정할 수 있음
	-  이어서 MySQL을 실행하는 Amazon RDS 데이터베이스로 스키마를 변환
	- DMS 복제 인스턴스를 설정할 수 있고요, 지속적 복제를 위해 Full load와 Change Data Capture CDC를 함
	- 온프레미스에서 소스 Oracle 데이터베이스를 읽어서 데이터 마이그레이션을 수행하고, 데이터를 프라이빗 서브넷(타켓 DB인 Mysql)에 삽입
- DMS에는 멀티 AZ 배포가 있음
	- 한 AZ에 DMS 복제 인스턴스가 있고, 그 인스턴스를 또 다른 AZ에 동기화 복제를 하게 되고, 그게 스탠바이 레플리카가 됨
- 하나의 AZ에서 고장이 발생했을 때 회복력을 갖게 되고 Data Redundancy 를 갖게 되어서 I/O 멈춤 현상을 없애고 latency spikes를 최소화할 수 있음
### RDS와 Aurora Mysql Migrations
- RDS 데이터베이스를 Aurora MySQL로 옮기고자 할 경우에 사용
- 첫번째는 RDS MySQL 데이터베이스의 스냅샷을 생성해서 이 스냅샷을 MySQL Aurora 데이터베이스에서 복원하는 것
	- 가동을 중지한 뒤 Aurora로 마이그레이션해야 하기 때문에 다운타임이 발생
- 두 번째는 좀 더 지속적인 방법으로 Amazon Aurora 읽기 전용 복제본을 RDS MySQL에 생성하는 것
	- 복제본의 지연이 0이 되면 Aurora 복제본이 MySQL과 완전히 일치한다는 뜻으로 이때 복제본을 데이터베이스 클러스터로 승격시키면 됨
	- 데이터베이스 스냅샷보다는 시간이 많이 걸리고, 복제본 생성과 관련한 네트워크 비용도 발생할 수 있음
- MySQL 데이터베이스가 RDS 외부에 있는 경우에는 `Percona XtraBackup` 기능을 사용하여 백업할 수 있음
	- 백업 파일을 생성하여 Amazon S3에 두면 Amazon Aurora의 기능을 사용해서 새로운 Aurora MySQL DB 클러스터로 백업 파일을 가져올 수 있음
	- Percona XtraBackup에서만 사용할 수 있음
- mysqldump 기능을 MySQL 데이터베이스에서 실행하여 기존 Amazon Aurora 데이터베이스로 출력값을 내보내는 것
	- 시간이 많이 들고 Amazon S3를 사용하지 않음
- Amazon DMS를 이용해서 두 데이터베이스가 가동되는 채로 이 데이터베이스 간 지속적인 복제를 진행하는 방법
	- PostgreSQL에서도 방법은 같음
- RDS 쪽은 유사한 방법으로 스냅샷을 생성해 Amazon Aurora 데이터베이스에서 복원하거나 PostgreSQL의 읽기 전용 복제본을 Amazon Aurora에 생성하여 복제 지연이 0이 될 때까지 기다렸다가 데이터베이스 클러스터로 승격시킬 수 있음
- 외부 PostgreSQL 데이터베이스를 Aurora에 마이그레이션하는 경우 백업을 생성한 다음 해당 백업을 Amazon S3에 두고 데이터를 가져오기 위해 aws_s3 Aurora 확장자를 사용해서 새로운 데이터베이스를 생성하는 방법도 있음
- DMS를 통해 PostgreSQL에서 Amazon Aurora로 지속적 마이그레이션이 가능
### AWS를 통한 온프레미스 전략
- **클라우드에서의 온프레미스 전략**
- Amazon Linux 2 AMI를 ISO 형식의 가상 머신으로 다운로드 할 수 있고 이 ISO 이미지를 VM을 생성하는 소프트웨어로 로드할 수 있음
	- Oracle VM과 Microsoft Hyper-V에 해당하는 VMWare, KVM Virtual Box를 포함
	- 직접 VM을 통해 온프레미스 인프라에서 Amazon Linux 2를 실행할 수 있게 됨
		- 사용자 데이터로도 이걸 작동할 수가 있다는 뜻
- VM 가져오기와 내보내기 기능이 있는데 이 기능을 통해 기존의 VM과 애플리케이션을 EC2로 마이그레이션 할 수 있음
	- 재해 복구 리포지토리 전략도 생성할 수 있음
	- 온프레미스 VM이 많은 경우 이를 클라우드에 백업하고 싶을 때 가져오기, 내보내기 기능을 통해 VM을 EC2에서 온프레미스 환경으로 다시 빼올 수도 있음
- AWS 애플리케이션 `Discovery Service`는 온프레미스의 정보를 모아주고 마이그레이션을 계획할 수 있게 해 주는 서비스
	- 상위 수준의 서비스이지만 서버 사용량 정보와 종속성 매핑에 대한 정보를 제공
	- 온프레미스에서 클라우드로 대량의 마이그레이션 할 때 유용
	- AWS Migration Hub를 사용해서 모든 마이그레이션을 추적할 수도 있음
- AWS data Migration Service(DMS)는 온프레미스에서 AWS로의 복제를 허용하고, AWS에서 AWS로, AWS에서 온프레미스로 복제를 허용
	- MySQL나 Postgres 데이터베이스가 온프레미스에 있고, AWS로 워크로드를 옮기고 싶다면 DMS를 써서 그동안 데이터베이스를 복제하고 준비가 됐을 때 AWS만을 사용해서 처리할 수 있기 때문
	- Oracle, MySQL DynamoDB 등 다양한 데이터베이스들과 함께 작동해서 사용하기에 편리
		- MySQL에서 DynamoDB로 데이터를 마이그레이션 하는 등
- AWS Server Migration Service(SMS)가 있음
	- 온프레미스의 라이브 서버들을 AWS로 증분 복제할 때 쓰는데 AWS로 볼륨을 직접 복제할 수 있음
	- 지속적인 복제 유형에 적용되는 증분 복제
- 온프레미스에서 AWS로의 마이그레이션 방법
- 온프레미스에서 가능한 것은 온프레미스와 EC2에 대한 VM 가져오기와 내보내기가 있었고, 애플리케이션 Discovery Service AWS와 같은 마이그레이션 서비스 Migration Hub DMS, SMS 등의 서비스
### AWS 백업 - 개요
- AWS Backup은 완전 관리형 서비스이며 AWS 서비스 간의 백업을 중점적으로 관리하고 자동화할 수 있게 도와줌
- 실제 중앙 시스템이 없고, 사용자 지정 스크립트나 매뉴얼을 만들 필요도 없이 백업 전략으로 AWS Backup을 생각해 볼 수 있음
	- 예를 들어 Amazon EC2, EBS, Amazon S3, RDS 및 모든 데이터베이스 엔진이 지원되고, Aurora, DynamoDB, DocumentDB Amazon Neptune, EFS, 그리고 Lustre와 Windows 파일 서버를 포함하는 FSx가 지원되며 AWS Storage Gateway의 볼륨 게이트웨이 등으로 시간이 지나면 더 늘어남
- 리전 간 백업을 지원하므로 한 곳의 재해 복구 전략을 다른 리전에 푸시할 수 있고 계정 간 백업도 지원
	- AWS에서 여러 계정을 사용할 경우에 도움이 됨
- Aurora와 같은 지정 시간 복구(PITR)를 지원하고, 온디맨드와 함께 예약된 백업을 지원
- **태그 기반 백업 정책**이 있어 예를 들어 프로덕션 태그가 지정된 리소스만 백업할 수 있음
- 백업 정책에서 백업 플랜(Plan)도 만들 수 있음
	- 백업 빈도를 정의하여 매 12시간 또는 매주, 매달 및 cron 표현식을 정하고 백업 기간도 지정
- 백업을 콜드 스토리지로 이전할지 여부도 결정
	- 보내지 않거나 일정 기간 후 보낼 수 있음
- 백업 보유 기간도 정함
	- 계속 보유하거나 일, 주, 월 년으로 기간을 정할 수 있음
- AWS Backup 과정
	- 백업 플랜을 만들고 나서 백업 대상이 되는 중요한 특정 AWS 리소스를 할당
	- 할당이 완료되면 데이터가 자동으로 Amazon S3에 백업됨
	- AWS Backup에 지정된 내부 버킷에 백업
- AWS Backup의 볼트(Vault) Lock
	- WORM(Write Once Read Many) 정책을 시행하면 백업 볼트(Vault)에 저장한 백업을 삭제할 수 없게 됨
	- 볼트 잠금 정책 덕분에 백업을 삭제할 수 없으며 백업에 대한 추가 방어막을 제공
	- 의도치 않거나 악의적인 삭제 작업을 막을 수 있음
	- 백업 유지 기간 축소 또는 변경 작업을 방지
- 기능이 활성화되면 루트 사용자도 백업을 삭제할 수 없음
- 백업의 안전성을 강력하게 보장
### Application Migration Service (MGN)
- 클라우드로 이동하는 것에 대해서는 사용 사례가 두 개 있음
- 예를 들어 새롭게 시작하면서 클라우드를 바로 활용하고 싶은 경우라면 마이그레이션할 필요는 없음, 하지만 온프레미스 서버나 데이터 센터가 있어서 클라우드로 마이그레이션하려면, 마이그레이션을 계획해야 함
- 한 가지 방법은 `AWS Application Discovery` 서비스로 마이그레이션을 계획하는 것
- 서버를 스캔하고 마이그레이션에 중요한 서버 설치 데이터 및 종속성 매핑에 대한 정보를 수집 
	- 어떻게 마이그레이션할지, 무엇을 먼저 마이그레이션할지 알 수 있음
- 마이그레이션은 두 가지 방법으로 할 수 있는데 하나는 Connector를 사용하는 Agentless Discovery
	- 가상 머신, 구성, CPU와 메모리 및 디스크 사용량과 같은 **성능 기록**에 대한 정보를 제공
- 또는 Application Discovery 에이전트를 실행할 수도 있음
	- 가상 머신 내에서 더 많은 업데이트와 정보를 얻을 수 있음
	- 예를 들어, 시스템 구성, 성능, 실행 중인 프로세스, 시스템 사이의 네트워크 연결에 대한 세부 정보 등을 얻을 수 있음, 종속성 매핑을 얻는 데 좋음
- 모든 결과 데이터를 AWS Migration Hub라는 서비스에서 볼 수 있음
- Application Discovery 서비스는 이동해야 할 항목과 그것들이 내부적으로 어떻게 상호 연결되어 있는지 파악하기에 유용
- 온프레미스에서 AWS로 이동하는 가장 간단한 방법은, AWS Application Migration Service, 즉 MGN이라는 걸 사용
	- AWS Application Migration Service, MGN을 사용하여 리호스팅을 할 수 있음
	- Lift-and-shift 솔루션이라고도 하는데 물리적, 가상, 또는 클라우드에 있는 다른 서버를 AWS 클라우드 네이티브로 실행하는 것
- 작동 방식
	- OS, 앱, 데이터베이스가 있는 회사 데이터 센터가 있고, 디스크에서 실행된다고 가정
	- Application Migration Service를 실행하면 데이터 센터에 설치된 복제 에이전트가 디스크를 연속적으로 복제
		- 예를 들어, 저비용 EC2 인스턴스, EBS 볼륨이 데이터 복제를 갖게 됨
	- 컷오버를 수행할 준비가 되면, 스테이징에서 프로덕션으로 이동할 수 있음
		- 원하는 크기의 더 큰 EC2 인스턴스와 여러분이 필요한 성능에 맞는 EBS 볼륨을 갖게 되는 것
	- 즉, 데이터를 복제한 다음 어느 시점에서 컷오버를 수행하는 것
- 이 방법은 광범위한 플랫폼, 운영 체제, 데이터베이스를 지원하고요, 다운타임도 최소
- 이 서비스가 자동으로 수행하니까 관련 엔지니어를 고용할 필요가 없기 때문에 비용도 절감
### 대규모 데이터 세트를 AWS로 전송
- 대규모 데이터를 AWS로 전송하는 방법과 여러 제약에 따른 최적의 방식이 무엇인지에 대해간단히 요약
- 예를 들어 200TB의 데이터를 클라우드로 옮기고 싶다고 가정하고 현재 인터넷 연결 속도는 100 Mbps
- **공용 인터넷을 사용하는 방법(Over the internet)**이 있고 역시 또 **공용 인터넷을 사용해 사이트 간 VPN을 설치(site-to-site VPN)**하는 방법도 있음
	- 설치가 빠르고, 바로 연결이 가능
	- 200TB를 GB로 그다음 MB로 변환한 다음 Mb로 변환을 하니 8배를 곱함
	- 그리고 보유하고 있는 속도를 나눠서 100Mbps라면 1천6백만 초이니 185일이 소요
	- 인터넷 연결이 100Mbps라면 200TB의 데이터를 보내는 데 반년이 걸리는 셈
- Direct Connect를 통해 보내고 싶다면 연결 라인을 통해 1Gbps로 프로비저닝한다고 했을 때 먼저 <u>초기 설치에 시간이 오래 걸리는 것</u>을 감안해야 함
	- Direct Connect를 사용한다면 먼저 연결을 만드는 데에만 한 달 정도가 걸릴 수 있고, 연결이 만들어진 후에 첫 번째 연결보다는 10배 정도 빠름 -> 18.5일 정도
- Snowball을 쓰면 얼마나 걸릴까?
	- Snowball을 2~3개 주문
	- 퍼실리티(facility)에 동시에 도착하도록 병렬 주문
	- 약 일주일이 소요되게 됨
	- Snowball이 도착해서 로드하고 다시 싣고, AWS로 보내져서 데이터가 송신되어 종단 간 전송에 일주일 정도가 걸리는 것
	- Snowball을 통해 전송되고 있던 데이터베이스가 있었다면 DMS와 결합하여 나머지 데이터를 전송할 수 있음
- on-goging replication(지속적 복제)
	- Site-to-Site VPN 등의 기술을 사용할 수 있음
		- 지속적 복제에서는 당장 전송할 데이터 양이 적기 때문
	- Direct Connect나 DMS 또는 DataSync 등의 서비스를 사용
	- 데이터의 송수신을 도와주고 지속적이든 아니든 사이트 간 VPN이나 Direct Connect처럼 적합한 인터넷 라인을 통해 송신을 가능케 함
- Snowball은 대용량 **일회성 전송**에 더 많이 사용
	- Snowball은 AWS로 첫 번째 데이터를 보내는 속도를 올리기 아주 유용
- 가장 쉽고 빠르고 안정적으로 AWS에 데이터를 보내는 방법은? -> 데이터셋의 크기에 따라 답이 달라짐
### VMware Cloud on AWS
- 온프레미스에 데이터 센터가 있을 때 VMware Cloud로 데이터 센터를 관리하는 경우가 있음
	- vSphere 기반 환경과 가상 머신을 VMWare Cloud를 통해 관리
- VMware에 데이터 센터가 있는 고객은 데이터 센터의 용량을 확장하고, 클라우드와 AWS를 모두 사용하고 싶어 함
- 하지만 데이터 센터와 클라우드를 관리하는 데에는 계속 VMware Cloud를 이용하고 싶을 수 있음
- VMware Cloud on AWS의 핵심임
- 전체 VMware Cloud의 인프라를 AWS에서 확장함으로써 vSphere, vSAN, NSX 등에서 사용할 수 있음 -> VMware의 하위 서비스
- 첫 번째 사례로는 컴퓨팅 성능을 확장하여 데이터 센터에서 클라우드뿐 아니라 스토리지까지 컴퓨팅이 가능해져 VMWare 기반 워크로드를 AWS로 마이그레이션할 수 있음
- 또한 프로덕션 워크로드를 여러 데이터 센터 간 실행할 수 있고, 프라이빗, 퍼블릭, 하이브리드 클라우드 환경 모두 가능
- 그리고 마지막으로 재해 복구 전략으로도 활용할 수 있음
- 익숙한 소프트웨어 제품군을 이용해서 신속하게 클라우드에 액세스할 수 있기 때문
- 그리고 AWS 클라우드를 사용하므로 다양한 AWS 서비스를 이용할 수 있음
- Amazon EC2, Amazon FSx, S3, RDS Direct Connect, Redshift 등
