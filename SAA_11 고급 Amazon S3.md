### S3 생명 주기 규칙
- 객체를 다른 스토리지 클래스 사이에서 옮길 수 있음
- Standard -> Standard IA -> Intelligent Tiering -> One-Zone IA -> Glacier Instanct Retieval -> Glacier Flexible Retieval -> Glacier Deep Archive 로 옮길 수 있음
	- 상위는 하위에 포함된 모든 스토리지로 옮길 수 있음
- `라이프 사이클 규칙`에 의해 자동으로 옮길 수 있음
	- Transition Actions: 다른 스토리지 클래스로 이전하기 위해 객체를 설정함
		- 생성된지 60일 후 standard 클래스로 이전시킴
	- Expiration actions: 일정 시간 뒤에 만료되어 객체를 삭제하도록 설정
	- 접두사에 의한 지정 - prefix
		- 버킷 전체에 적용하거나 버킷 안 특정 경로에 적용 가능
	- 태그에 의한 지정
- 썸네일은 쉽게 재생성될 수 있고, 60일 동안 보관되어야 함. 소스 이미지는 60일 동안 즉시 불러와져야하며 그 후에는 최장 6시간을 기다릴 수 있다
	- 소스 이미지는 Standard에 있고, 60일 후 라이프사이클을 통해 Glacier로 옮긴다(아카이브화), 썸네일 이미지는 One-Zone IA에 있을 수 있음. 왜냐면 빈번히 액세스 하지 않고 쉽게 재생성 할 수 있기 때문. 60일 후 만료시키거나 삭제할 수 있는 라이프 사이클을 지정할 수 있음
- 삭제된 객체를 복구할 수 있어야 할 때 
	- S3 버저닝 사용 -> 삭제 마크를 가지고 삭제된 객체를 표시함
- Storage Class Analysis 를 이용해 분석을 활용할 수 있음
	- One zone IA나 Glacier에는 호환되지 않음
### 요청자 지불(Requester Pays)
- 기본 - 버킷 소유자가 버킷 관련된 비용을 지불한다 (스토리지 비용 + 네트워크 비용)
- 수많은 대형 파일이 있고, 일부 고객이 이를 다운로드할 경우 Requester Pays 버킷을 활성화 
	- 소유자가 아닌 요청자가 객체 데이터 다운로드 비용을 지불 - 네트워킹 비용 지불
	- 소유자는 버킷의 객체 스토리지 비용은 부담
- 대량의 데이터 셋을 다른 계정과 공유할 때 유용
- 요청자는 익명이어서는 안되기 때문에 AWS에서 인증을 받아야 함
### 이벤트 알림
- use caes에 따라 이벤트 알림을 만들고 `SNS 토픽이나 SQS Queue, Lambda` 등을 통해 다른 액션까지 연계 가능
- IAM 권한이 필요함
- SNS에 알림을 보내려면 SNS리소스 정책이 필요함, SQS는 SQS 리소스 정책이 필요함
- 이벤트는 Amazon EventBridge로 가기 때문에 규칙을 만들어 필터링해서 보낼 수도 있음
	- 18가지의 기능을 호출할 수 있음
	- Advenced filtering
	- multiple destination
	- eventBridge Capabilities
### S3 Performance(성능)
- 속도가 매우 빠름
- 버킷 내에서 접두사의 수 제한은 없음
- 접두사 = object path 
	- bucket/folder1/sub1/file -> /folder1/sub1/ 가 접두사가 됨
- 최적화
	- 멀티파트 업로드
		- 5기가 넘는 파일은 무조건 사용해야함, 100mb 이상부터 사용 권장
		- 업로드를 병렬화하기 때문에 전송 속도를 높여 대역폭을 최대화 할 수 있음
		- 파일 하나를 여러 파트(chunk)로 나누고, *S3에 병렬로 업로드 후 업로드 완료 후 하나의 파일로 합침*
	- S3 Transfer acceleration(가속화)
		- 미국에 있는 파일을 호주 S3에 업로드 할 때 미국에 있는 `엣지 로케이션`을  이용해 빠르게 업로드 후 호주 S3 버킷에 올릴 수 있음(private 네트워크를 이용) -> 전송 가속화
		- 퍼블릭을 최소화 프라이빗을 최대한 사용
	- S3 byte range fetches
		- 다운로드 시 사용 가능 -> 다운로드 시 파트로 다운되는데 병렬로 처리
		- 파일에서 특정 바이트 범위를 가져와 GET요청을 병렬화
			- 바이트 범위를 가져오는 걸 실패하면 더 작은 단위의 바이트로 가져오기 때문에 안전
		- 파트 데이터 일부분만을 검색할 경우 
### Select & Glacier Select
- 모든 데이터를 검색하고 필터링 거는 것보다 서버측에서 필터링을 하고 검색하면 sql문으로 간단히 필터링을 걸어 행과 열을 찾을 수 있음 -> 네트워크 전송이 줄어 데이터 검색과 필터링에 드는 클라이언트 측의 CPU 비용이 줄어듦
- 적은 네트워크 전송 및 cpu를 적게 씀
- 간단한 필터링에 추천
### Batch Operations
- 대량 작업 수행
- 한 번에 많은 S3 객체의 메타데이터와 프로퍼티를 수정할 수 있고, 배치 작업으로 S3 버킷 간에 객체를 복사할 수 있음
- **S3 버킷 내 암호화되지 않은 모든 객체를 암호화 할 수 있음** 
- ACLs, tags 변경 가능, Glacier에서 한 번에 많은 객체를 복원할 수 있음
- 작업은 객체의 목록, 수행할 작업 옵션 매개 변수로 구성됨
- 재시도를 관리할 수 있고, 진행 상황을 추적 가능, 보고서 생성 기능 등이 제공됨
- S3 인벤토리의 객체목록을 이용해 S3 Select 파일 필터링이 가능함
- S3 Batch Operations를 사용하면 재시도를 관리할 수 있고 진행 상황을 추적하고 작업 완료 알림을 보내고 보고서를 생성할 수 있어서 직접하는 것보다 권장
- S3 배치에 전달할 객체목록은 S3 Inventory라는 기능을 사용해 가져옴
- S3 Select를 사용해 필터링
- S3 Batch Operations에 수행할 작어브 매개 변수와 함께 객체 목록을 전달
- S3 Inventory를 사용해 암호화 되지 않은 객체를 찾아 S3 Batch Operations으로 암호화 할 수 있음
