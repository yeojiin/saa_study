
###  메시징 소개
- 미들웨어로 다른 서비스간 커뮤니케이션이 필요할 때
-  동기 커뮤니케이션
	-  애플리케이션이 또 다른 애플리케이션과 직접적으로 연결
	-  ex) 온라인 커머스 서비스에서 물건이 판매될 때 배송 서비스에 연락 해 물건을 배송함
	-  구매 서비스와 배송 서비스는 직접적으로 연결 -> **동기 커뮤니케이션**
	- 구매 서비스가 배송 서비스에게 배송 요청
- 비동기(이벤트 기반)
	- 대기열 등으로 불리는 **미들웨어가 애플리케이션들을 연결**
	- 구매 서비스가 '누군가 물건을 구매했으니 이를 대기열에 포함시키겠다' 고 알림
	-  배송 서비스가 대기열에게 최근 구매 내역 있는지 물어봄(리스너)
	- 대기열이 요소를 반환하면 배송 서비스 로직 처리
	- 구매 서비스와  배송 서비스가 직접 연결되어 있진 않음 -> `비동기`
-  대기열 모델에는 SQS,  pub/sub 모델의 경우 SNS, 실시간 스트리밍을 하고 대용량 데이터는 Kinesis로 분리할 수 있음

### Amazon SQS -   표준  Queues
- SQS의 핵심은 **대기열**
- 생산자: SQS 대기열에 메세지를 전송하는 주체, 1개 이상일 수 있음
- 소비자: 대기열의 메세지를 처리하고 수신하는 대상 -> 대기열 메세지 폴링 후 처리 후 삭제
- 대기열 서비스: 생산자와 소비자 사이를 분리하는 `버퍼 역할 `
-  완전 관리형 서비스, `어플리케이션 분리`
-  장점
	- 처리량이 무제한
	- 지연시간이 짧아 매우 빠르게 응답을 받지 않으면 메시지가 소실될 수 있음
	- SQS 메세지는 작아야 함
	- 중복 메세지가 존재할 수 있는데 **적어도 한 번의 전송을 목표로 함**
- 생산자
	- 최대 256KB의 메시지가 생산자에 의해 SQS로 전송됨
	- 생산자는 SDK 소프트웨어 개발 키트를 사용하여 SQS에 메시지를 보냄 
	- SQS에 메시지를 보내는 API를 SendMessage
	- 메시지가 삭제됐다는 것은 메시지가 처리됐다는 뜻
-  소비자
	-  대기열에는 소비가가 있고 소비자는 SQS 메시지를 폴링함
	-  소비자는 아마 한 번에 최대 10개의 메세지를 받음
	- 메세지 처리 후  소비자가 이 메시지들을 DeleteMessage API로 대기열에서 삭제
	- 여러 소비자를 동시에 가질 수 있음
	-  SQS 대기열은 메세지를 동시에 수신하고 처리할 소비자를 여러 개 가질 수 있음
	-  더 많은 메시지가 있어서 처리량을 늘려야 하면 소비자를 추가하고 **수평 확장을** 수행
	- CloudWatch 지표 사용 가능, 알림 가능, ASG 기능 가능
-  SQS 보안
	- HTTPS API를 사용하여 메시지를 보내고 생성함으로써 비행 중 암호화를 하고 KMS 키를 사용하여 미사용 암호화를 얻고, 원한다면 클라이언트 측 암호화를 할 수도 있음 ->  클라이언트가 자체적으로 암호화 및 암호 해독을 수행
	- 액세스 제어를 위해 IAM 정책은 SQS API에 대한 액세스를 규제할 수 있고, S3 버킷 정책과 유사한 SQS 액세스 정책도 있음

### SQS 메시지 가시성 시간 초과
- 메시지 가시성 시간 초과 (Message Visibility Timeout) :  소비자가 메시지를 폴링하면 그 메세지는 다른 소비자들에게 보이지 않게 됨
- ex) 왼쪽에서 오른쪽으로 가는 시간이 있고. 컨슈머가 ReceiveMessage 요청을 하고 있음,  대기열에서 메시지가 반환됨 -> 가시성 시간 초과가 시작됨
	- 기본값으로 메시지 가시성 시간 초과는 30초 -> 30초동안 메세지가 처리되어야 함
	- 그동안 다른 소비자가 메세지 요청 API를 호출해도 메세지가 반환되지 않음
	- 하지만 가시성 기간 초과가 경과되고, 메세지가 삭제되지 않을 경우 **메세지는 대기역에 다시 넣음**
	- 그러면 다른 소비자 또는 동일한 소비자가 ReceiveMessage API 호출을 하면 이전의 그 메시지를 또 받게 됨
	- 가시성 시간 초과 기간 내에 메시지를 처리하지 않으면 **메시지가 두 번 처리될 수도 있음**
	- 메시지를 처리하는 데 시간이 더 필요하다는 것을 알고 있는데 메시지를 처리하지 않아 가시성 시간 초과 기간을 벗어날 때는 ChangeMessageVisibility라는 API 사용
		-  소비자가 메시지를 처리하는 데 시간이 더 필요하다는 것을 알고 있고, 해당 메시지를 두 번 처리하고 싶지 않다면 소비자는 ChangeMessageVisibility API를 호출하여 SQS에 알려야 함
- 시간은 적절히 정하고 ChangeMessageVisibility API를 활용하는 것이 좋음

### SQS 롱 폴링
-  소비자가 대기열에 메시지를 요청하는데 대기열에 아무것도 없다면 메시지 도착을 기다리면 됨 -> `롤 폴링`
-   지연 시간을 줄이기 위해
-  SQS로 보내는 API 호출 숫자를 줄이기 위해
	- ex) 비어 있는 SQS 대기열이 있음, 소비자가 대기열에 폴링, 최대 20초 동안 폴링, -> 대기열이 비어 있다면 기다림
	- 소비자가 여전히 롱 폴링 중인데 메세지가 들어오면 자동적으로 그 메시지가 소비자에게 전송됨
	- 이때의 지연 시간은 짧아서 자동으로 최대한 빨리 받게 됨
	- 롱 폴링은 SQS로의 API 호출 숫자를 줄임
	-  애플리케이션의 효율성과 대기 시간을 증가시킴: 1~20초로 구성 가능
-  대기열 레벨에서 구성하여 폴링하는 아무 소비자로부터 롱 폴링을 활성화하는 방법 1
- WaitTimeSeconds를 지정함으로 소비자가 스스로 롱 폴링을 하도록 선택하는 방법 2
- SQS 대기열에 대한 API 호출 수를 최적화하고, 지연 시간을 줄이는 법 -> 롤 폴링

### FIFO QUEUES
- FIFO는 선입선출
- 대기열에 첫 번째로 도착한 메시지가 대기열을 떠날 때도 첫 번째
- 순서가 더 확실히 보장
- ex) 
	-  첫 번째, 두 번째, 세 번째 그리고 네 번째 메시지를 보냄
	- SQS FIFO 대기열은 소비자가 SQS FIFO 대기열로부터 메시지를 불러올 때 정확히 동일한 순서로 메시지를 받음
	- SQS 대기열의 처리량에는 제한이 있음
	- 묶음이 아닐 경우에는 초당 300개의 메시지를 처리하고,  메시지를 묶음으로 보낸다면  처리량은 초당 3,000개
- 중복을 제거하도록 해주는 SQS FIFO 대기열의 기능으로 인해 정확히 한 번만 보낼 수 있음
- 분리가 발생하거나 메시지의 순서를 유지할 필요가 있을 때 FIFO 대기열을 사용하면 됨
- SQS로 너무 많은 메시지를 보내지 않도록 처리량에 제한도 할 수 있음
- Content-based deduplication라는 설정 -> 5분 이내의 짧은 시간 동안 동일한 메시지가 두 번 발송됐을 경우 **중복을 방지**하는 설정

### SQS + 오토스케일링 그룹
- SQS 대기열과 오토 스케일링 그룹이 있을 때 ASG 내의 EC2 인스턴스에 메시지를 SQS 대기열에서 폴링함
- 오토 스케일링 그룹을 자동으로 대기열 크기에 따라 확장시키기 위함,  CloudWatch 지표인 대기열 길이를 보고 결정할 수 있음
- ApproximateNumberOfMessages라고 하는 지표는 대기열에 몇 개의 메시지가 남아 있는지를 표시
	- 이를 기반으로 경보를 지정할 수 있는데 가령 이 지표가 1,000을 넘는 경우 1,000개의 메시지가 대기열에서 처리를 기다리고 있다는 뜻으로 **처리에 지연이 발생하고** 있음을 파악할 수 있음
	-  경보를 생성하여 1,000개의 메시지가 대기 중임을 경보를 통해 알리면 경보가 EC2 인스턴스가 충분하지 않음을 근거로 오토 스케일링 그룹에 확장 동작을 트리거 함
	- 오토 스케일링 그룹에 더 많은 EC2 인스턴스가 추가되며 확장이 이루어져 메시지가 훨씬 더 빨리 처리됨
	- SQS 대기열의 크기는 줄어들어 이에 대한 축소 또한 실행됨
	- 
- **확장이나 축소 모두 가능**
- ex) 세일 행사를 진행 중, 주문은 여러 유형의 데이터베이스에 저장될 수 있는데 Amazon RDS나 OLTP 유형 데이터베이스를 필요로 하는 경우라면 Amazon Aurora  NoSQL 유형 데이터베이스가 필요하면 Amazon DynamoDB에 저장할 수 있음
	- 트랜잭션 내역은 상당히 빠른 속도로 순식간에 RDS나 Aurora에 쓰임
	- 애플리케이션이 주문 즉 요청을 처리할 때  데이터베이스가 오버로드되는 등 이유로 **특정 트랜잭션에 오류가 발생**
	- 고객 트랜잭션은 유실
	- `쓰기 대상 데이터베이스에서 SQS를 버퍼로 해결`
	- 동일한 데이터베이스와 프론트엔드 애플리케이션이 있다고 하면 데이터베이스에 바로 요청을 쓰는 대신 애플리케이션이 요청, 즉 트랜잭션을 일명 무한히 확장 가능한 **SQS 대기열에 먼저 쓰는** 방법
	-  처리량 문제가 발생하지 않음
	- 애플리케이션에 요청이 전송되고, 요청은 메시지로 대기열에 안착하는데 이는 곧 모든 트랜잭션, 즉 모든 요청이 SQS 대기열에 메시지로서 전달됨 -> 데이터 유실이 사라짐
- 분리나 급격히 증가한 로드 혹은 시간초과 등의 문제에서 신속한 스케일링 필요? -> SQS 대기열

### Amazon Simple Notification Service(AWS SNS)
- 메시지 하나를 여러 수신자에게 보낸다고 가정 -> `직접 통합을 (Direct integration)` 쓸 수 있음
- ex) 구매 서비스 애플리케이션에서  이메일 알림을 보내고 사기 탐지 서비스와 배송 서비스 그리고 SQS 대기열에도 메시지를 보낼 수 있음
	-  하지만 수신 서비스를 새로 추가할 때마다 통합을 생성하고 작성해야 하므로 번거로움
	- 대신 Pub/Sub 즉, 게시/구독이라는 것을 사용할 수 있음
	- `구매 서비스가 메시지를 SNS 주제로 전송`할 수 있습니다
	- 메시지를 주제로 게시
	- 해당 주제에는 많은 구독자가 있으며 각 구독자는 SNS 주제에서 해당 메시지를 수신하고,  이를 보관 -> Pub/Sub 패턴
	- 이벤트 생산자:  한 SNS 주제에만 메시지를 보냄
	- 이벤트 수신자 또는 구독자: 주제와 관련한 SNS 알림을 받으려는 사람, 해당 주제로 전송된 메시지를 모두 받게 됨, 그리고 메시지를 필터링하는 기능을 사용하는 경우에도 메시지를 받을 수 있음
- 주제별 최대 구독자 수 -> 1200만 이상의 구독자까지 가능
- SNS에서 직접 이메일을 보낼 수도 있고, SMS 및 모바일 알림을 보낼 수도 있고,  지정된 HTTP 또는 HTTPS 엔드 포인트로  직접 데이터를 보낼 수도 있음
-  SNS는 SQS와 같은 특정 AWS 서비스와 통합하여  메시지를 대기열로 직접 보낼 수도 있고,  메시지를 수신한 후 함수가 코드를 수행하도록 Lambda에 보내거나  Firehose를 통해 데이터를  Amazon S3나 Redshift로 보낼 수도 있음
- CloudWatch 경보 Auto Scaling 그룹 알림, CloudFormation State Changes Budgets, S3 버킷, DMS, Lambda, DynamoDB RDS 이벤트 등
-  SNS 게시 방법
	-  SDK 주제 게시를 사용해 SNS에 메시지를 게시할 수 있음
	- 주제를 만든 다음 하나 또는 여러 개의 구독을 만들고,  SNS 주제에 게시
	- 모든 구독자가 자동으로 해당 메시지를 받게 됨
	- 혹은 모바일 앱 SDK 전용 직접 게시 방법 -> 플랫폼 애플리케이션을 만든 다음 플랫폼 엔드 포인트를 만들고,  플랫폼 엔드 포인트에 게시
	- 수신 가능 대상은 Google, GCM, Apple APNS, Amazon ADM 구독자
	- 모두 모바일 애플리케이션으로 알림을 수신하게 됨
- 보안 측면에서 Amazon SNS는 SQS와 동일
- 전송 중 암호화와 KMS 키를 사용한 저장 데이터 암호화가 있고,  클라이언트가 SNS에 암호화된 메시지를 보내려는 경우를 위한 클라이언트 측 암호화가 있음
- 암호화 및 암호 해독은 클라이언트 몫
- 액세스 제어는 `IAM 정책 중심`
- SNS 액세스 정책을 정의 -> SNS 주제에 교차 계정 액세스 권한을 갖거나 S3 이벤트와 같은 서비스가 SNS 주제에 작성할 수 있도록 허용하려는 경우 매우 유용

### SNS 및 SQS - 팬아웃 패턴
-  메시지를 여러 SQS 대기열로 보내고 싶은데 모든 SQS 대기열에 개별적으로 메시지를 보내면 문제가 발생할 수 있음
- ex) 애플리케이션이 중간에 비정상적으로 종료될 수도 있고 전달에 실패한다거나 SQS 대기열이 더 추가될 수 있음 -> `팬 아웃 패턴` 사용
- SNS 주제에 메시지를 전송한 후 원하는 수의 SQS 대기열이 이 SNS 주제를 구독
-  대기열들은 구독자로서 SNS로 들어오는 모든 메시지를 받게 됨
- 구매 서비스가 있고 두 개의 SQS 대기열로 메시지를 보낼 경우 직접 보내는 대신 메시지를 하나의 SNS 주제로 보내고 대기열들이 이 SNS 주제를 구독하여 사기 탐지 서비스나 배송 서비스가 각자의 SQS 대기열에서 모든 메시지를 읽어 들임 -> **완전히 분리된 모델이며 데이터도 손실되지 않음**
- SQS로 작업을 다시 시도할 수 있을 뿐 아니라 데이터 지속성, 지연 처리도 수행할 수 있음
- 더 많은 SQS 대기열을 추가 가능
- SQS 액세스 정책에서 SNS 주제가 SQS 대기열에 쓰기 작업을 할 수 있도록 허용해야 함
- 리전 간 전달도 가능
- ex) 이벤트 세 개를 여러 대기열에 넣는 경우를
	-  S3 이벤트 규칙에 제한 조건이 있음
	-  객체 생성과 같은 이벤트 유형과 /images와 같은 접두사 조합이 동일하다면 S3 이벤트 규칙은 한 가지여야 합니다, 만약 여러 대기열에 동일한 S3 이벤트 알림을 보내고 싶을 경우
	-  팬아웃 패턴을 사용
	- S3 객체를 생성하여 S3 버킷에 이벤트를 형성하고, 이벤트를 SNS 주제로 전송한 후 팬아웃 패턴으로 많은 SQS 대기열이 SNS 주제를 구독하게 함
	- 다른 유형의 애플리케이션, 이메일, Lambda 함수 등도 구독할 수 있음
	- Amazon S3에서 발생하는 이벤트의 메시지가 여러 다른 목적지에 도달할 수 있음
	- 다른 아키텍처에서는 Kinesis Data Firehose (KDF)를 통해 SNS에서 Amazon S3로 직접 데이터를 전송할 수 있음
	- SNS를 KDF에 직접 연결하여 구매 서비스에서 데이터를 SNS 주제로 전송할 수 있음
	- Kinesis Data Firehose, 즉 KDF에서 해당 정보를 수신하고 해당 KDF에서 Amazon S3 버킷으로 전달하거나 특정한 KDF 목적지로 어디든 전달할 수 있음
-  SQS FIFO를 활용하여 팬아웃을 수행하려면 팬아웃, 순서, `중복 제거가 필요`
- 구매 서비스가 데이터를 SNS FIFO 주제로 전달하고 두 개의 SQS FIFO 대기열로 팬아웃한 후 사기 탐지 서비스와 배송 서비스가 이 FIFO 대기열에서 데이터를 읽어 들임
- 팬아웃 패턴과 관련하여 정말 편리한 SNS의 기능은 SNS에서 메시지 필터링을 할 수 있음
- SNS 주제를 구독할 때 전송되는 메시지를 필터링하는 데 사용되는 JSON 정책 -> 메세지 필터링
-  ex) 구매 서비스가 있고 이 서비스에서 SNS 주제로 트랜잭션을 보냄
	-  트랜잭션에는 순서가 있고 제품은 연필이며 개수는 네 개로 발주 완료 상태
	- 발주된 주문만 골라서 SQS 대기열을 만들고자 한다면  SQS 대기열이 SNS 주제를 구독하게 하고 JSON으로 필터링 정책을 적용해야 함
	- 정책에서 상태를 ‘발주 완료’로 지정하면 해당하는 메시지만  SQS 대기열에 들어감
	- 반면 취소된 주문을 고르는 필터링 정책을 만들면 전과 동일한 SNS 주제에서 취소된 주문에 해당하는 SQS 대기열을 만들 수 있음
	-  발주된 주문과 취소된 주문에 해당하는 SQS 대기열에는 같은 메시지가 도달하지 않음

### Kinesis
- Kinesis:  활용하면 실시간 스트리밍 데이터를 손쉽게 수집하고 처리하여 분석할 수 있음
-  실시간 데이터에는 애플리케이션 로그, 계측, 웹 사이트 클릭 스트림, IoT 원격 측정 데이터 등 어떤 것도 포함
-  데이터가 빠르게 실시간으로 생성된다면 모두 실시간 데이터 스트림으로 간주
- Kinesis는 네 가지 서비스
	-  Kinesis Data Stream에서는 데이터 스트림을 수집하여 처리하고, 저장
	- Kinesis Data Firehose에서는 데이터 스트림을 AWS 내부나 외부의 데이터 저장소로 읽어 들임
	- Kinesis Data Analytics에서는 SQL 언어나 Apache Flink를 활용하여 데이터 스트림을 분석
	- Kinesis Video Stream에서는  비디오 스트림을 수집하고 처리하여 저장

### Kninesis Data Stream 개요
- 시스템에서 큰 규모의 데이터 흐름을 다루는 서비스
- 여러 개의 샤드로 구성되어 있고 이 샤드는 1번, 2번에서 N번까지 번호가 매겨짐
- 생산자가 있고, 생산자는 데이터를 Kinesis Data Stream으로 보냄, 생산자는 다양함
- Kinesis Agent를 활용해서 스트리밍할 서버, Kinesis 스트림에서 애플리케이션 로그를 처리할 수 있음
- 모든 생산자는 정확히 동일한 작업을 함
- 낮은 수준에서 SDK에 의존하며 Kinesis Data Stream에 레코드를 전달
	- 레코드는 두  가지 요소로 구성
		-  파티션 키와 최대 1MB 크기의 데이터 블롭으로 구성
		-  파티션 키는 레코드가 이용할 샤드를 결정하는 데 사용되고,  데이터 블롭은 값 자체를 의미
		- 생산자는 데이터를 스트림으로 보낼 때 초당 1MB를 전송하거나 샤드당 1초에 천 개의 메시지를 전송할 수 있음
- 소비자에도 다양한 종류 있음
	- SDK에 의존하거나 높은 수준에서는 Kinesis Client Library, KCL에 의존하는 애플리케이션이 있고,  Kinesis 스트림에서 서버리스로 처리하려는 경우 Lambda 함수도 가능
	- Kinesis Data Firehose도 있고 Kinesis Data Analytics도 있음
	- 소비자가 레코드를 받으면 여기에는 파티션 키, 샤드에서 레코드의 위치를 나타내는 시퀀스 번호, 데이터 자체를 의미하는 데이터 블롭이 있음
	- Kinesis Data Stream에는 여러 소비 유형이 존재
		- 샤드마다 초당 2MB의 처리량을 모든 소비자가 공유할 수 있음
		-  소비자마다 샤드당 1초에 2MB씩 받을 수도 있음 -> 효율성을 높인 소비 유형
	- **생산자가 Kinesis Data Stream에 데이터를 전송하고 데이터는 잠시 거기에 머물면서 여러 소비자에게 읽힙니다** 
	- Kinesis Data Stream의 특징
		- 보존 기간은 1일에서 365일 사이로 설정 가능
		-  데이터가 일단 Kinesis로 들어오면 삭제할 수 없음 -> `불변성`
		- 데이터 스트림으로 메시지를 전송하면 파티션 키가 추가되고 파티션 키가 같은 메시지들은 같은 샤드로 들어가게 되어 키를 기반으로 데이터를 정렬할 수 있음
		- 생산자는 SDK, Kinesis Producer Library (KPL), Kinesis Agent를 사용하여 데이터를 전송할 수 있고,
		- 소비자는 Kinesis Client Library (KCL)나 SDK를 써서 직접 데이터를 작성할 수 있음
		- AWS에서 관리하는 Lambda나 Kinesis Data Firehose, Kinesis Data Analytics를 활용할 수도 있음
	- Kinesis Data Stream에는 두 가지 용량 유형
		- 전통적인 용량 유형: `프로비저닝 유형`
			- 프로비저닝할 샤드 수를 정하고 API를 활용하거나 수동으로 조정
			- 샤드를 프로비저닝할 때마다 시간당 비용이 부과됨
			- 사전에 사용량을 계획할 수 있을 경우 유리
		-  온디맨드라
			- 프로비저닝을 하거나 용량을 관리할 필요가 없음
			- 시간에 따라 언제든 용량이 조정 가능
			- 시간당 스트림당 송수신 데이터양(GB 단위)에 따라 비용이 부과됨
			- 사전에 사용량을 예측할 수 없을 경우 유리
			- 
- Kinesis Data Stream의 보안
	- 리전에 배포되고요, 여기 샤드가 있음
	- IAM 정책을 사용하여 샤드를 생성하거나 샤드에서 읽어 들이는 접근 권한을 제어
	- HTTPS로 전송 중 데이터를 암호화할 수 있으며 미사용 데이터는 CMS로 암호화할 수 있음
	- 클라이언트 측에서 데이터를 암호화하거나 해독할 수 있으며 이를 **클라이언트 측 암호화**
	-  Kinesis에서 VPC 엔드포인트를 사용할 수 있음 ->  Kinesis에 인터넷을 거치지 않고 프라이빗 서브넷의 인스턴스에서 직접 손쉽게 접근 가능
	- 모든 API 요청은 CloudTrail로 감시할 수 있음

### Kinesis Data Firehose
- 생산자에서 데이터를 가져올 수 있는 유용한 서비스, 생산자는 Kinesis Data Stream에서 본 무엇이든 될 수 있음
- 애플리케이션, 클라이언트, SDK, KPL, Kinesis Agent 모두 Kinesis Data Firehose로 생산할 수 있음
- Kinesis Data Stream과 아마존 CloudWatch (로그 및 이벤트),  AWS IoT도 Kinesis Data Firehose로 생산할 수 있습니다, 이 모든 애플리케이션이 Kinesis Data Firehose로 데이터를 전송하면 Kinesis Data Firehose는 람다 기능을 활용해 데이터를 변환할지 선택할 수 있음
- 소스에서 데이터를 가져오는데 주로 Kinesis Data Stream, 수신처에 데이터를 쓸 수 있음
-  Kinesis Data Firehose가 데이터 쓰는 법을 알기 때문에 별도로 코드를 쓸 필요가 없음
- Kinesis Data Firehose의 수신처
	- AWS 수신처
	- 아마존 S3
		- 모든 데이터를 아마존 S3에 쓸 수 있음
		- 데이터 웨어하우스인 아마존 레드시프트도 있는데, 여기에 데이터를 쓸 때는 먼저 아마존 S3에 데이터를 쓰면 Kinesis Data Firehose가 복사 명령어를 내보냄
		- 복사 명령어가 아마존 S3의 데이터를 아마존 레드시프트로 복사
	- 아마존 ElasticSearch
	-  써드 파티 파트너 수신처도 있습니다, 데이터독, 스플렁크, 뉴렐릭, 몽고DB와 같은 곳으로 Kinesis Data Firehose가 데이터를 전송할 수 있음
	- **Kinesis Data Firehose가 데이터를 전송할 수 있는 파트너들이 있음**
	-  만약 HTTP 엔드포인트가 있는 자체 API를 보유하고 있다면 Kinesis Data Firehose를 통해 커스텀 수신처로 데이터를 보낼 수 있음
	- 모든 데이터를 백업으로 S3 버킷에 보내거나, 혹은 수신처에 쓰이지 못한 데이터를 실패 S3 버킷에 보낼 수도 있음
	- Kinesis Data Firehose는 완전 관리되는 서비스, 관리가 필요하지 않으며, 자동으로 용량 크기가 조정되고, 서버리스이므로 관리할 서버가 없음
	- 레드시프트와 아마존 S3, ElasticSearch와 같은 AWS 수신처로 데이터를 보낼 수도 있고, 스플렁크, 몽고DB, 데이터독, 뉴렐릭 등 써드 파티 파트너로 보낼 수도 있으며 어떤 HTTP 엔드포인트든 커스텀 수신처로도 보낼 수 있음
	-  Kinesis Data Firehose를 통하는 데이터에 대해서만 비용을 지불하면 되므로  훌륭한 데이터 과금 모델
	- 실시간에 가까운 서비스-> Kinesis Data Firehose에서 수신처로 데이터를 배치로 쓰기 때문
	- 람다를 활용해 자체적인 데이터 변환도 쓸 수 있음
	- 실패한 혹은 모든 데이터를 백업S3 버킷에 보낼 수 있음
	- Kinesis Data Stream은 데이터를 대규모로 수집할 때 쓰는 스트리밍 서비스고, 생산자와 소비자에 대해 커스텀 코드를 쓸 수 있음, 실시간으로 이루어지며 약 70ms 혹은 200ms 정도의 지연시간이 발생, 용량을 직접 조정할 수 있어 샤드 분할이나 샤드 병합을 통해 용량이나 처리량을 늘릴 수 있음, 제공한 용량만큼 비용을 지불하면 되며, 데이터는 1일에서 365일간 저장됨
	- 여러 소비자가 같은 스트림에서 읽어 올 수 있고, 반복 기능도 지원
	- Kinesis Data Firehose도 수집 서비스로 데이터를 아마존 S3나 레드시프트, ElasticSearch 써드 파티 파트너나 자체 HTTP로 스트리밍
	- 완전 관리되며, 서버리스이고, 근 실시간으로 이뤄짐
	- `근 실시간(near real-time)`
	- 데이터 스토리지가 없어 Kinesis Data Firehose의 데이터를 반복하는 기능은 지원되지 않음

### Kiensis 와 SQS FIFO 데이터 정렬
- ex) 도로에 트럭이 100대 있고, 각각 트럭 ID가 있음, GPS 위치를 주기적으로 AWS에 보냄, 이제 각 트럭의 순서대로 데이터를 소비해서 트럭의 이동을 추적하고, 경로를 순서대로 확인
	- `파티션 키를 이용해 ` Kinesis로 데이터를 전달
	- 파티션 키 값은 트럭 ID
	- 트럭 1은 트럭 1의 파티션 키를 전송하고,  트럭 2는 트럭 2의 파티션 키를 전송, 
	- 같은 파티션 키를 지정하면 해당 키가 언제나 동일한 샤드로 전달
	- 각 트럭의 파티션 키는 거기에 따른 샤드에 속함
	- 트럭 1은 계속 트럭 1이라는 동일한 파티션 키를 전송하므로 데이터가 언제나 같은 샤드로 이동
	- 그러므로 트럭 1의 다음 데이터 지점은 샤드 1로 가고, 트럭 3의 다음 데이터 지점도 샤드 1번으로 계속 이동
	- 안정된 파티션 키를 얻으면 바로 트럭이 그 데이터를 같은 샤드로 전달하고, 샤드 레벨에서 각 트럭의 순서에 따른 데이터를 얻을 수 있음
- SQS 표준 방식
	- 순서가 없음
	- SQS FIFO라는 선입 선출 방식이 존재
	- SQL FIFO의 그룹 ID를 사용하지 않으면 모든 메시지가 소비되는 방식은 보내진 순서에 따르며 소비자는 하나만 존재
	- 소비자는 하나이기 때문에 두 배치의 메시지를 소비
	- 트럭이 있다면, 모든 트럭이 FIFO 대기열로 데이터를 보내더라도 소비자는 하나
	- 만약 소비자 숫자를 스케일링하고, 서로 연관된 메시지를 그룹화하려는 경우 `그룹 ID를 사용`
	- FIFO 대기열은 FIFO 내부에 두 개 그룹이 생기고, 그룹마다 각각 소비자를 가질 수 있게 됨
	- **그룹 ID가 많을수록 소비자도 많아짐**
	- Kinesis와 SQS의 차이점
		- 트럭은 100대가 있고 Kinesis 샤드가 5개 SQS FIFO 대기열이 1개라면 Kinesis 데이터 스트림에서 평균적으로 가지는 값은 샤드당 트럭 20대
		- 해시 기능 덕분에 각 트럭은 하나의 샤드에 지정되고, 해당 샤드에 계속 머물 것
		- 트럭 데이터는 각 샤드에 순서대로 정렬
		- 동시에 가질 수 있는 최대 소비자 개수는 5개 -> 샤드가 5개이고, 샤드마다 하나의 소비자가 필요하기 때문
		- Kinesis 데이터 스트림은 샤드가 5개인 경우에 초당 최대 5MB의 데이터를 수신할 수 있으며 처리량이 많음
		-  트럭 10,000대가 많은 데이터를 전송하고,  Kinesis 데이터 스트림에 샤드당 데이터를 정렬할 때 사용하기 좋음
		- SQS FIFO의 경우 SQS FIFO 대기열은 하나
		-  샤드 및 파티션을 정의할 필요 없음
		- 트럭이 100대 있으므로 각 트럭 ID에 상응하는 그룹 ID를 100개 생성
		- 소비자도 최대 100개가 될 수 있음
		- **그룹 ID 숫자에 따른 동적 소비자 수를 원할 때 사용하면 좋은 모델**


### SQS vs SNS vs Kinesis
- SQS
	- 소비자가 SQS 대기열에서 메시지를 요청해서 데이터를 가져오는(pull) 모델
	- 데이터를 처리한 후 소비자가 대기열에서 삭제해서 다른 소비자가 읽을 수 없도록 해야 함
	- 작업자나 소비자 수는 제한이 없음 -> 작업자와 소비자가 함께 소비하고 대기열에서 삭제
	- 관리된 서비스이므로 처리량을 프로비저닝할 필요가 없고,  빠르게 수백 수천 개의 메시지로 확장할 수 있음
	- 순서를 보장하려면 FIFO 대기열 활성화
	- 메시지에 지연 기능이 있어 30초 등 일정 시간 뒤에 대기열에 나타나도록 할 수 있음
-  SNS
	- 게시/구독 모델로 다수의 구독자에게 데이터를 푸시하면 메시지의 복사본을 받게 됨
	- SNS 주제별로 1,250만 명의 구독자까지 가능
	- 데이터가 한 번 SNS에 전송되면 지속되지 않음 -> 제대로 전달되지 않는다면 데이터를 잃을 가능성이 있음
	- 게시-구독 모델은 최대 10만 개의 주제로 확장 가능
	- 처리량을 프로비저닝하지 않아도 되고, SQS와 결합 가능
	- 팬아웃 아키텍처 패턴을 이용하면 SNS와 SQS를 결합하거나 SNS FIFO 주제를 SQS FIFO 대기열과 결합할 수 있음
- Kinesis
	- 소비자가 Kinesis로부터 데이터를 가져오는(pull) 표준 모드
		-  샤드당 2 MB/s의 속도를 지원
	- 향상된 팬아웃 유형의 소비 메커니즘에서는 
		- Kinesis가 소비자에게 데이터를 푸시하며 샤드 하나에 소비자당 2 MB/s의 속도
	-  처리량 높음 ->  많은 애플리케이션 읽기가 가능
	-  데이터가 지속됨 -> 데이터 재생 가능 -> 실시간 빅 데이터 분석, ETL 등에 활용
	-  샤드 레벨에서 정할 수 있어 Kinesis 데이터 스트림마다 원하는 샤드 양을 지정해야 함
	- 샤드를 직접 확장해서 데이터가 언제 만료될지 정함
	- 프로비저닝 용량 모드
		- Kinesis 데이터 스트림으로부터 원하는 샤드 양을 미리 지정
	- 온디맨드 용량 모드
		- 샤드 수가 Kinesis 데이터 스트림에 따라 자동으로 조정

### Amazion MQ
- 클라우드 네이티브 서비스
- 온프레미스에서 기존 애플리케이션을 실행하는 경우 개방형 프로토콜인 MQTT, AMQP, STOMP, WSS Openwire 등을 사용
- 애플리케이션을 클라우드에 마이그레이션하는 경우에는 SQS, SNS 프로토콜 혹은 API를 사용하기 위해 애플리케이션을 다시 구축하고 싶지 않고, MQTT, AMQP 등과 같은 기존에 쓰던 프로토콜을 사용하고 싶을 수 있는데 이때 Amazon MQ를 사용
- RabbitMQ와 ActiveMQ 두 가지 기술을 위한 `관리형 메시지 브로커 서비스`
- RabbitMQ와 ActiveMQ는 온프레미스 기술로 개방형 프로토콜 액세스를 제공
- Amazon MQ를 이용하면 해당 브로커의 관리형 버전을 클라우드에서 사용할 수 있음
- Amazon MQ는 무한 확장이 가능한 SQS나 SNS처럼 확장성이 크지는 않음
- Amazon MQ는 서버에서 실행되므로 서버 문제가 있을 수 있기 때문
- 고가용성을 위해 장애 조치와 함께 다중 AZ 설정을 실행할 수 있음
- Amazon MQ는 SQS처럼 보이는 대기열 기능과  SNS처럼 보이는 주제 기능을 단일 브로커의 일부로 제공
-  Amazon MQ의 고가용성 
	- us-east-1라는 리전에 us-east-1a와 us-east-1b 두 개의 가용 영역이 있음
	- 영역 하나는 활성 상태 그리고 또 다른 영역은 대기 상태
	- 두 영역에 각각 활성, 대기 상태인 Amazon MQ 브로커를 추가
	- 장애 조치 실행을 위해 백엔드 스토리지에 Amazon EFS도 정의
	- 대기 상태 영역 역시 Amazon EFS에 마운트되므로 첫 번째 활성 대기열과 동일한 데이터를 가질 수 있고,  장애 조치도 올바르게 실행
	- 클라이언트가 Amazon MQ 브로커와 통신해서 장애 조치가 실행되는 경우에도 Amazon EFS 덕분에 데이터가 저장됨
