### 암호화 101
- 전송 중 암호화
	- 매우 민감한 기밀 내용인 경우 전송 중 암호화 사용
	- 가령 신용카드로 온라인 결제를 하려고 할 때 네트워크 패킷이 가는 길에 다른 사람한테 신용카드 번호가 보여서는 안됨
	- 온라인으로 결제할 때 초록색 자물쇠 그림이 있고 SSL이 활성화된 웹사이트임을 보장해주는 HTTPS 웹사이트라면 전송 중 암호화가 됨
	- 전송 중 암호화가 되면 데이터가 전송되기 전 암호화되고, 서버가 데이터를 받으면 복호화
	- 하지만 전송하는 이와 서버만이 암호화와 복호화를 하는 방법을 알고 있음
	- SSL 인증서가 암호화를 해주고, 다른 방법은 HTTPS가 있음
- Amazon 서비스를 다룰 때마다 HTTPS 엔드포인트가 있어서 전송 중 암호화가 됐음을 보장
- 이제 전체 웹, 거의 전체 웹이 SSL과 HTTPS에서 실행되어야 함
- 활성화하면 '중간자' 공격으로부터 보호
- DynamoDB 같은 AWS의 HTTP 웹 사이트와 통신하려고 할 때 비밀 데이터를 추가하고, SSL 암호화로 암호화한 다음 네트워크를 통해 보내면 웹사이트에서 데이터를 수신합니다 웹사이트는 복호화하는 방법을 알고 있음
- 서버 측 저장 데이터 암호화
- 데이터가 서버에 수신된 후 암호화
- 그래서 그 전에는 서버가 데이터를 받아서 복호화를 하고 암호 복호화된 형식에 사용
- 서버는 데이터를 디스크에 저장
- 서버가 데이터를 암호화된 형태로 저장하고 있다는 것
- 서버가 해킹을 당하면 데이터가 복호화 되어서는 안되기 때문
- 데이터는 클라이언트로 다시 전송되기 전에 복호화
- 즉, 데이터 키라고 불리는 키 덕분에 데이터는 암호화된 형태로 저장되고, 암호 키와 해독 키는 주로 KMS Key Management Service 같은 곳에 따로 관리됨
- 서버는 Key Management Service와 통신할 수 있어야 함
- 객체가 있고 이 객체를 예를 들어 EBS로 전송
- 객체는 어떤 메커니즘으로든 전송되고, EBS는 데이터 키를 써서 그 데이터의 암호화를 수행하고, 암호화된 형태로 저장
- 해당 데이터를 어떤 이유에서든 검색하려고 할 때 EBS 같은 AWS가 우리 대신 데이터 키를 통해 복호화를 하면 복호화된 데이터가 가령 HTTP, HTTPS를 거쳐 돌아옴
- 서비스의 서버 자체가 암호화와 복호화를 관리하고, 데이터 키를 통해 접근
- 클라이언트 측 암호화
- 클라이언트 측 암호화에서 데이터는 클라이언트가 암호화하고, 클라이언트는 우리고 서버는 그 데이터를 절대 복호화할 수 없고, 데이터를 받는 클라이언트에 의해 복호화
- 데이터는 서버에 저장되지만 서버는 데이터의 내용을 알 수 없음
- 서버는 최선의 방법으로도 데이터를 복호화할 수 없어야 함
- 봉투 암호화
- 객체가 있고 클라이언트는 데이터 키를 사용해서 클라이언트 측의 데이터를 암호화함
- 데이터 키로 암호화를 수행
- 해당 데이터를 원하는 데이터 저장소로 보냄
- FTP가 될 수도 있고 S3도 될 수 있고 무엇이든 상관 없음
- Amazon이나 여러분이 원하는 다른 곳에 데이터를 저장
- 데이터를 받으면 클라이언트는 암호화된 객체를 받고, 데이터 키에 액세스가 있거나 다른 곳으로부터 데이터 키를 찾을 수 있으면 받은 데이터를 복호화하여 복호화된 객체를 얻게 됨 -> 암호화는 클라이언트 측에서 수행
- 서버 데이터 저장소는 데이터를 암호화하거나 복호화할 수 없고, 암호화된 데이터를 받기만 할 수 있음

### KMS 개요
- AWS 서비스에서 암호화 = 대부분은 KMS 암호화
- KMS 서비스가 우리를 대신해서 암호화 키를 관리한다는 개념
- KMS는 물론 승인에 관해 IAM과 완벽히 통합, KMS로 암호화가 되어 있다면 데이터에 대한 액세스를 아주 쉽게 제어 가능
- AWS KMS의 강점은 그걸 쓰면 여러분은 CloudTrail을 통해 키를 사용하기 위해 이루어진 모든 API 호출을 감사할 수 있음
- KMS는 대부분의 AWS 서비스에서 원활하게 사용 가능
	- EBS 볼륨에 저장되어 있는 데이터를 암호화하고 싶으면 KMS 통합을 활성화하면 됨
	- S3, RDS, SSM 등도 같음
	- 
- KMS를 사용하려 한다면 API 호출을 통해서도 KMS를 사용할 수 있음
- AWS CLI나 SDK를 사용할 수 있어 모든 비밀을 KMS 키로 암호화할 수 있음
- 그 암호화된 비밀을 예를 들어 여러분의 코드나 환경 변수에 저장할 수 있음 -> 코드에 비밀 내용을 저장지 않아도 됨
- KMS 키 = KMS 고객 마스터 키
- 대칭 KMS 키가
	- 데이터를 암호화하고 복호화하는 데 사용되는 암호화 키가 하나만 있다는 의미
	- KMS가 통합된 모든 AWS 서비스는 대칭 키를 사용
	- MS 대칭 키를 생성하거나 사용할 때 키 자체에는 절대로 액세스할 수 없음
	- AWS API 호출을 이용해서 그 키를 사용
- 비대칭 키
	- 키가 2개 있다는 의미
	- 하나는 데이터를 암호화하는 데 사용되는 **퍼블릭 키**고 다른 하나는 데이터를 복호화하는 데 사용되는 **프라이빗 키**
	- 암호화/복호화 또는 서명/확인 형태의 작업을 할 때 사용
	- KMS에서 퍼블릭 키를 다운로드할 수 있지만 프라이빗 키에는 액세스할 수 없음
	- 프라이빗 키에 액세스하려면 역시 API 호출만 사용할 수 있음
	- AWS Cloud 외부에서 KMS API 키에 액세스할 수 없는 사용자에 의해 암호화 필요한 경우퍼블릭 키를 써서 데이터를 암호화하고 그걸 여러분에게 전송. 그리고 계정 안에 있는 AWS의 프라이빗 키를 써서 그 데이터를 복호화
- KMS 키 안에는 다양한 타입의 KMS 키 존재
	- AWS가 소유한 키
	- 무료
	- SSE-S3 타입의 암호화를 사용하거나 SSE DynamoDB를 사용할 때 사용하는 키
	- DynamoDB가 소유한 키를 선택할 수 있음
- AWS 관리형 키
	- 무료
	- 앞에 aws/가 있고 서비스 이름이 나오기 때문에 그것들을 알아볼 수 있음
	- aws/rds 또는 aws/ebs 혹은 이 예에서와 같이 aws/dynamodb 같은 이름
	- 키가 지정된 서비스 안에서만 사용할 수 있음
- 고객 관리형 키
	- 한달에 1달러의 비용이 발생
	- 가져오고 싶으면 임포트할 수 있음, 그리고 한달에 1달러를 지불
	- KMS도 가격이 책정되어 있고, 서비스에 대해 이루어진 API 호출 건에 대해 지불하게 됨
	- 대략 10,000회의 API 호출당 3센트
	- 자동 키 순환 : 키가 AMS 관리형 KMS 키라면 자동으로 1년마다 순환
	- KMS 안에서 생성한 고객 관리형 키라면 여러분이 자동 순환을 활성화해야 함
	- 1년마다 순환, 만일 임포트한 KMS 키라면 수작업으로만 순환시킬 수 있음
	- 별명을 사용 필요
-  KMS 키의 범위는 리전
- KMS 키로 암호화된 EBS 볼륨이 예를 들어 eu-west-2에 있다면 다른 리전에 복사하기 위해서는 몇 가지 단계 필요
- EBS 볼륨의 스냅샷을 찍어야 하고, 그리고 암호화된 스냅샷의 스냅샷을 찍으면 그 스냅샷 자체도 동일한 KMS 키로 암호화 됨
-  그리고 스냅샷을 다른 리전에 복사하기 위해 우린 다른 KMS 키를 사용해서 그 스냅샷을 다시 암호화해야 함
- 동일한 KMS 키가 두 리전에 있을 수 없음
- 다른 키를 써서 KMS로 암호화된EBS 스냅샷이 있고 다른 리전에 있게 됨
- KMS를 이용해서 그 스냅샷을 원래의 EBS 볼륨으로 복구, 그리고 그 KMS 키 B는 ap-southeast-2에 속함
- KMS 키에 대한 액세스를 관리하기 위한 정책
- 키에 KMS 키 정책이 없다면 아무도 키에 접근할 수 없음
- 기본 정책
	- 특정한 커스텀 KMS 키 정책을 제공하지 않았을 때 생성
	- 기본값은 여러분의 계정에 있는 모든 사람이 이 키에 액세스하도록 허용하는 것
	- 사용자 또는 역할이 이 키 정책에 액세스하도록 허용하는 IAM 정책이 있다면 문제가 없음
- 더 구체적으로 통제하고 싶다면 커스텀 KMS 키 정책
	- KMS 키에 액세스할 수 있는 사용자와 역할을 정의, 키를 누가 관리할 수 있는지 정의
	- KMS 키에 대한 교차 계정 액세스를 하려는 경우에 특히 유용
	- 다른 계정이 KMS 키를 사용하도록 승인할 수 있음
	- 암호화된 스냅샷을 계정들 간에 복사하고 싶을 때 사용,고객 관리형 KMS 키로 암호화된 스냅샷을 생성, 커스텀 키 정책을 첨부해야 되기 때문에 반드시 고객 관리형 KMS 키가 되어야 함, 그리고 교차 계정 액세스를 승인하기 위한 KMS 키 정책을 첨부
	- 암호화된 스냅샷을 타깃 계정과 공유. 그리고 타깃 계정 안에서 우린 스냅샷의 사본을 생성, 다른 고객 관리형 키를 사용해서 그 타깃 계정 안에서 암호화 후 타깃 계정 안에서 스냅샷으로부터 볼륨을 생성할 수 있음
### KMS - Multi-Region Keys
- AWS KMS에는 다중 리전 키를 둘 수 있음
- 선택된 한 리전에 기본 키를 갖는다는 의미
- us-east-1에 기본 키를 두면 다른 리전으로 복제. us-west-2, eu-west-1 ap-southeast-2로 복제. 유사해 보이는 것은 키 구성 요소가 복제되기 때문
- 다른 리전도 동일한 키를 갖게 되는데 키 ID가 완전히 똑같음
- key/mrk 뒤에 붙은 문자들이 전체 리전에 걸쳐 동일
- 다른 AWS 리전에서 사용할 수 있는 KMS 키 세트로 서로 교차해서 사용할 수 있음
- 한 리전에서 암호화한 다음 다른 리전에서 복호화 할 수 있음
- 다중 리전 키는 동일한 키 ID와 동일한 키 구성 요소를 갖음
- 기본 키의 자동 교체를 활성화했고 실제로 자동으로 교체된 키는 다른 리전에도 복제됨
- 다중 리전 키의 핵심은 한 리전에서 암호화하고 다른 리전에서 복호화해 다음 리전으로 복제할 때나 교차 리전 API 호출을 실행할 때 데이터를 재암호화하지 않아도 된다는 점
- 하지만 KMS 다중 리전 키는 전역으로 사용할 수 없다는 점
- 기본 키가 있고 복제본이 있는 것
- 각 다중 리전 키는 자체 키 정책 등으로 각각 독립적으로 관리
- 특정 사용 사례를 제외하고는 다중 리전 키 사용을 권장하지 않음 -> KMS 키는 단일 리전에 제한되는 것을 선호
- 다중 리전 키의 사용 사례
	- 전역 클라이언트 측 암호화
	- 한 리전에서 클라이언트 측 암호화를 하고, 다른 리전에서 클라이언트 측 복호화
	- DynamoDB 전역 테이블이나 Global Aurora에서 암호화하는 데도 사용
	- DynamoDB 전역 테이블과 KMS 다중 리전 키를 클라이언트 측 암호화하는 원리는?
	- 중요한 것은 전체 테이블만 암호화하는 게 아니라는 점
	- 저장 데이터 암호화이므로 테이블의 속성을 암호화하여 특정 클라이언트만 사용할 수 있게 됨
	- 데이터베이스 관리자도 사용할 수 없음
	- 이때 Amazon DynamoDB 암호화 클라이언트를 사용
	- us-east-1과 ap-southeast-2를 예로 들어 us-east-1의 KMS 다중 리전 키는 다른 리전에 복제. ap-southeast-2에
	- 클라이언트 애플리케이션에서 DynamoDB에 데이터를 삽입하려면 먼저 속성을 암호화해야 함
	- 다중 리전 키를 사용해 암호화할 속성을 암호화
	- DynamoDB 테이블 필드는 클라이언트 측 암호화가 되지 않지만 가령 사회 보장 번호는 암호화될 것
	- DynamoDB 테이블에 액세스할 수 있는 데이터베이스 관리자가 '사회 보장 번호' 속성을 암호화하는 데 사용한 KMS 키에 액세스할 수 있는 권한이 없다면 액세스할 수 없음
	- 데이터베이스 관리자로부터도 보호할 수 있음
	- DynamoDB 테이블이 전역 테이블인 경우 해당 테이블의 데이터는 다른 리전으로 복제됨. ap-southeast-2로 복제
	- 다중 리전 키로 데이터 속성을 암호화하기로 했기 때문에 ap-southeast-2 리전의 클라이언트 애플리케이션은 열을 검색해서 해당 속성이 암호화됐는지 확인한 후 API 호출을 실행해 복제된 다중 리전 키를 사용해 해당 속성을 복호화
	- ap-southeast-2의 클라이언트 애플리케이션이 KMS로 로컬 API 호출을 보내 해당 속성을 복호화
	- 클라이언트 측 암호화 기술을 사용하면 데이터의 특정 필드나 속성을 보호할 수 있음
	- API 키 액세스 권한이 있는 클라이언트만 복호화할 수 있음
	- 또한 전역 테이블 덕분에 데이터뿐만 아니라 암호화 키도 함께 복제할 수 있음
- Global Aurora의 개념도 유사
- AWS Encryption SDK를 사용
- 두 개의 리전이 있고, 두 리전에 걸쳐 복제된 KMS 다중 리전 키가 있음
- 클라이언트 애플리케이션이 SSN 열을 암호화하려면 데이터를 Amazon Aurora DB에 테이블로 삽입해야 함
- 해당 행에서 다중 리전 키인 MRK로 암호화된 SSN 열을 제외한 다른 열의 데이터는 암호화되지 않음
- 전역 데이터베이스이므로 테이블이 전역으로 복제될 것
- ap-southeast-2에도 동일한 데이터가 생김
- ap-southeast-2의 클라이언트는 테이블에서 암호화된 데이터를 가져오고, 다중 리전 키를 사용해 KMS에 로컬 API 호출을 보내 해당 속성을 복호화 -> 지연 시간 단축
- 클라이언트 측 암호화를 사용하면 DB 관리자로부터도 데이터를 보호할 수 있음
- Amazon Aurora DB에 액세스할 수 있는 DB 관리자가 '사회 보장 번호' 열에 액세스하고자 할 때 KMS 키에 대한 액세스 권한이 없으면 해당 데이터를 읽을 수 없음
### S3 암호화된 복제
- 한 버킷에서 다른 버킷으로 S3 복제를 활성화하면 암호화되지 않은 객체와 SSE-S3로 암호화된 객체가 기본으로 복제
- 고객 제공 키인 SSE-C로 암호화한 객체도 복제될 수 있음
- SSE-KMS로 암호화된 객체도 존재
- 기본적으로 복제되지 않지만 만약 객체를 복제하려면 옵션을 활성화해야 함
- 어떤 KMS 키로 대상 버킷 내 객체를 암호화하는지 지정해야 함
- KMS 키 정책을 대상 키에 적용해야 하고, S3 복제 서비스를 허용하는 IAM 역할을 생성해서 소스 버킷의 데이터를 먼저 복호화하도록 한 뒤 대상 KMS 키로 대상 버킷의 데이터를 다시 암호화 필요
- 복제가 활성화되는데 이는 수많은 암호화와 복호화가 발생하기 때문
- KMS 스로틀링 오류가 발생한 경우는 서비스 할당량을 요청해야 함
- S3 복제에 다중 리전 키를 사용해야 할까?
	- S3 복제에 다중 리전 키를 사용할 수 있으나 현재는 Amazon S3 서비스에서 독립 키로 취급하고 있으므로 객체는 여전히 복호화될 것이고, 다중 리전 키인 경우에도 동일한 키로 암호화

### 암호화된 AMI 공유 프로세스
- AMI를 다른 계정과 공유하는 과정에 관한 것으로 AMI는 KMS 키로 암호화 되어 있음
- AMI는 소스 계정에 있고 KMS 키로 암호화된 것
- A 계정의 AMI에서 B 계정의 EC2 인스턴스를 시작할까?
	- 시작 권한으로 AMI 속성을 수정해야 하는데 이 시작 권한은 B 계정에서 AMI를 시작하도록 허용
	- 이렇게 AMI를 공유
	- 시작 권한을 수정하고 특정 대상인 AWS 계정 ID를 추가하는 것
	- 다음 B 계정에서 사용하도록 KMS 키도 공유해야 하므로 일반적으로 키 정책으로 실행
	- B 계정에서 KMS 키와 AMI를 모두 사용할 수 있는 충분한 권한을 가진 IAM 역할이나 IAM 사용자를 생성
	- 따라서 DescribeKey API 호출과 ReEncrypted API 호출, CreateGrant, Decrypt API 호출에 관한 KMS 측 액세스 권한이 있어야 함
	- 모두 완료된 후에는 AMI에서 EC2 인스턴스를 시작하면 되는데 선택 사항으로 대상 계정에서 자체 계정의 볼륨을 재암호화하는 KMS 키를 이용해 전체를 재암호화할 수 있음
	- 이제 EC2 인스턴스를 실행할 수 있음

### SSM 매개변수 저장소 개요
- SSM Parameter Store는 구성 및 암호를 위한 보안 스토리지
- 구성을 암호화할지 선택할 수 있으므로 KMS 서비스를 이용해 암호를 만들 수 있음
- SSM Parameter Store는 서버리스이며 확장성과 내구성이 있고, SDK도 사용이 용이
- 매개변수를 업데이트할 때 구성과 암호의 버전을 추적할 수도 있음
- IAM을 통해 보안이 제공되며 특정한 경우에는 Amazon EventBridge로 알림을 받을 수도 있음
- CloudFormation과 통합 가능
- 즉 CloudFormation이 Parameter Store의 매개변수를 스택의 입력 매개변수로 활용할 수 있다는 뜻
- 예를 들어 애플리케이션과 SSM Parameter Store가 있을 때 평문 구성을 저장한다고 할 때 EC2 인스턴스 역할 같은 애플리케이션의 IAM 권한이 확인되거나 암호화된 구성이 있다고 가정
- SSM Parameter Store가 KMS로 구성을 암호화 필요
- KMS 서비스가 암호화 및 복호화에 사용된다는 뜻
- 암호화와 복호화를 수행하려면 애플리케이션이 기본 KMS 키에 액세스할 수 있어야 함
- 계층 구조가 있는 Parameter Store에 매개변수를 저장할 수 있음
- 예를 들어 /my-department/를 경로로 정의 하고, 하위에 my-app/ 그 하위에 dev/가 있고, 그 폴더 안에 db-url과 db-password가 있다고 가정
- 매개변수가 계층 구조 아래로 쭉 내려가는 것
- 상위로 한 단계 올라가 prod/의 매개변수가 될 db-url, db-password도 저장할 수 있고, other-app/이나 /other-department/로 올라갈 수도 있음
- 여러분이 원하는 방식으로 매개변수를 구조화할 수 있음
- 구조화를 통해 IAM 정책을 간소화하여 애플리케이션이 /my-department/ 혹은 my-app/ 전체 경로에 혹은 my-app/ 또는 /my-department/ 환경의 특정 경로에만 액세스할 수 있도록 함
- 레퍼런스를 사용해 Parameter Store로 Secrets Manager의 암호에 액세스할 수도 있음
- AWS에서 발행하는 퍼블릭 매개변수도 사용할 수 있는데 특정 리전에서 Amazon Linux 2의 최신 AMI를 찾으려 할 때 Parameter Store에서 API 호출을 대신해 쓸 수 있음
-  Dev Lambda 함수라는 애플리케이션을 사용한다면 my-app/ 내 dev/의 db-url과 db-password에 액세스를 허용하는 IAM 역할을 할 것
- IAM 정책과 일부 환경변수 때문에 Prod Lambda 함수를 사용한다면 다른 경로에 있는 prod/의 db-url과 db-password에도 액세스할 수 있음
- Systems Manager에는 두 가지 매개변수 티어가 있는데 바로 표준과 고급
- 큰 차이는 용량으로 각각 4KB, 8KB
- 표준 티어에선 적용되지 않고 고급 티어에선 적용됨
- 고급 티어는 월 0.05달러를 지불해야 하지만 표준 티어는 무료
- 고급 매개변수에서만 사용할 수 있는 매개변수 정책이란 무엇일까?
	- 매개변수 정책을 통해 만료 기한을 뜻하는 타임 투 리브(TTL)를 매개변수에 할당할 수 있음
	- 사용자가 비밀번호 등의 민감한 정보를 업데이트 또는 삭제하도록 강제
	- 한 번에 여러 정책을 할당할 수도 있음
	- 매개변수를 삭제하는 만료 정책을 예시
	- 타임스탬프에서는 이 매개변수를 반드시 삭제해야 함
	- 그리고 EventBridge와 통합함으로써 EventBridge에서 알림을 받을 수 있게 됨
	- 매개변수가 만료되기 15일 전에 EventBridge 알림을 받게 됨 
	- TTL로 매개변수가 삭제되기 전에 업데이트할 수 있을 만큼 기간 여유가 충분
	- 매개변수를 변경하고 싶을 때?
		- EventBridge는 변경이 없다는 알림도 제공하므로 20일 동안 매개변수에 업데이트가 없으면 알림을 받게 됨

### AWS Secrets Manager - 개요
- AWS Secrets Manager는 암호를 저장하는 최신 서비스로 SSM Parameter Store와는 다른 서비스
- Secrets Manager는 X일마다 강제로 암호를 교체하는 기능이 있어 암호 관리를 더 효율적
- AWS Secrets Manager로 교체할 암호를 강제 생성 및 자동화할 수 있음
- 새 암호를 생성할 Lambda 함수를 정의해야 함
- AWS Secrets Manager는 AWS가 제공하는 다양한 서비스와도 아주 잘 통합됨
- Amazon RDS, MySQL PostgreSQL, Aurora 등
- AWS 외 여러 서비스와 데이터베이스에도 즉시 통합할 수 있음
- 데이터베이스에 접근하기 위한 사용자 이름과 비밀번호가 AWS Secrets Manager에 바로 저장되고 교체 등도 가능하단 것
- 암호는 KMS 서비스를 통해 암호화됨
- RDS와 Aurora의 통합 혹은 암호에 대한 내용이 시험에 나오면 AWS Secrets Manager
- 다중 리전 암호의 개념
- 복수 AWS 리전에 암호를 복제할 수 있고, AWS Secrets Manager 서비스가 기본 암호와 동기화된 읽기 전용 복제본을 유지한다는 개념
- 두 리전이 있을 때 기본 리전에 암호를 하나 만들면 보조 리전에 동일한 암호가 복제됨
- us-east-1에 문제가 발생하면 암호 복제본을 독립 실행형 암호로 승격할 수 있음
- 여러 리전에 암호가 복제되니 다중 리전 앱을 구축하고 재해 복구 전략도 짤 수 있음
- 한 리전에서 다음 리전으로 복제되는 RDS 데이터베이스가 있다면 동일한 암호로 동일한 RDS 데이터베이스 즉 해당 리전의 해당 데이터베이스에 액세스할 수 있음

### AWS Certificate Manager (ACM)
- AWS Certificate Manager(ACM)는 TLS 인증서를  AWS에서 프로비저닝, 관리 및 배포하게 해줌
- TLS/SSL 인증서는 어디에 사용될까?
	- 웹사이트에서 전송 중 암호화를 제공하는 데 쓰임
	- 웹사이트에 방문했을 때 볼 수 있는 HTTPS의 S는 보안(secure)을 의미하며 이를 통해 트랜잭션에 TLS 인증서가 포함되어 있음을 알 수 있음
- 오토 스케일링 그룹에 연결된 ALB가 있다고 하면 이때 애플리케이션 로드 밸런서(ALB)를 HTTPS 엔드 포인트로서 노출하려 함
- 그러려면 ALB를 AWS Certificate Manager와 통합해 ALB에서 직접 TLS 인증서를 프로비저닝 및 유지관리하도록 하면 됨
- 사용자가 HTTPS 프로토콜을 사용하는 웹사이트 또는 API에 액세스하게 됨
- ACM은 퍼블릭과 프라이빗 TLS 인증서를 모두 지원하며 퍼블릭 TLS 인증서 사용 시에는 무료로 이용할 수 있음
- 인증서를 자동으로 갱신하는 기능도 있음
- AWS 서비스와 통합되어 있어 Elastic Load Balancer(ELB)에 TLS 인증서를 불러올 수 있음
- 예를 들면 클래식 로드 밸런서(CLB)와 애플리케이션 로드 밸런서(ALB) 그리고 네트워크 로드 밸런서(NLB)가 있음
- 또는 CloudFront 배포나 API Gateway의 모든 API에서도 불러올 수 있음
- 다만 ACM을 사용할 수 없는 곳이 하나 있는데 그건 바로 EC2 인스턴스
- 퍼블릭 인증서일 경우 추출이 불가능
- ACM을 통해 EC2 인스턴스에 대한 퍼블릭 인증서를 생성할 수 없단 것
- 퍼블릭 인증서는 어떤 과정을 통해 요청?
	- 인증서에 포함할 도메인 이름을 나열
	- corp.example.com과 같은 전체 주소 도메인 이름(FQDN)도 될 수 있고, *.example.com과 같은 와일드카드 도메인도 가능
	- 도메인 수에는 제한이 없음
	- 유효성 검증 방법 즉 DNS 검증과 이메일 검증 중 어느 것을 거칠지 선택
	- 자동화를 목적으로 SSL 인증서를 자동 갱신하려면 DNS 검증을 쓰는 편이 유리
	- 이메일 검증을 사용한다면 ACM이 도메인에 등록된 연락처로 이메일을 보내 해당 인증서를 요청했는지 여부를 확인
	- DNS 검증을 사용하기로 했다면 DNS 구성에서 CNAME 레코드를 생성해 도메인 소유권을 증명해야 함
	- Route 53이 있다면 ACM과 자동으로 통합해 이러한 작업을 수행
	- 몇 시간 후 유효성 검증이 완료되면 인증서가 발행되고, 이 퍼블릭 인증서도 자동 갱신 목록에 추가됨
	- 즉, ACM에서 스스로 생성된 모든 인증서를  만료 60일 전에 자동으로 갱신해 주니 무척 편리
- ACM에서 퍼블릭 인증서는 어떻게 가져오면 될까?
	- ACM 외부에서 생성된 인증서를 ACM으로 가져오는 옵션도 제공
	- ACM 외부에서 생성되었기 때문에 자동 갱신은 불가능
	- 인증서가 만료되기 전에 직접 새 인증서를 가져와야 함
	- ACM 서비스가 만료 45일 전부터 매일 만료 이벤트를 EventBridge 서비스에 전송해 줌 -> 기간 수정 가능
	- EventBridge를 통해 매일 인증서 만료 이벤트가 발생한다고 할 수 있음
	- EventBridge에서 Lambda 함수나 SNS 주제 또는 SQS 대기열을 트리거하는 것
	- AWS Config을 사용하는 방법도 있음
	- acm-certificate-expiration-check라는 관리형 규칙이 있는데 만료된 인증서를 확인하는 규칙인데 여기서 일수를 조정할 수도 있음
	- Config 서비스에 규칙을 설정하면 Config 서비스가 ACM 서비스를 검사해서 규칙에 위배되는 인증서가 있을 경우 규정 비준수 이벤트가 EventBridge로 전송됨
	- Lambda나 SNS, SQS를 트리거하는 거 함
- ACM 서비스는 어떻게 ALB와 통합되는 걸까?
	- 백엔드에 오토 스케일링 그룹이 있는 ALB와 ACM으로 프로비저닝 및 유지관리되는 TLS 인증서가 있다고 가정
	- ALB에서는 HTTP에서 HTTPS로의 리디렉션 규칙을 설정할 수 있음
	- 사용자가 HTTP 프로토콜에서 애플리케이션 로드 밸런서에 액세스할 때 ALB는 HTTPS로 리디렉션하는 요청을 반환하는 것
	- 사용자는 HTTPS 프로토콜에서 애플리케이션 로드 밸런서에 액세스하며 AWS Certificate Manager(ACM)에서 나오는 TLS 인증서를 사용
	- 요청이 HTTPS 프로토콜을 통과하면 오토 스케일링 그룹으로 곧바로 전달
- ACM이 API Gateway와 어떻게 통합되는지?
	- 엔드 포인트 유형
	- 먼저 엣지 최적화(edge-optimized) 유형이 있는데 이 유형은 글로벌 클라이언트를 위한 유형으로 먼저 CloudFront 엣지 로케이션으로 요청을 라우팅하여 지연을 줄이는 방법으로 하나의 리전에만 있는 API Gateway로 보내지는 경우
	- 리전(regional) 엔드 포인트 유형은 클라이언트가 API Gateway와 같은 리전에 있을 때를 쓰임
	- 이 경우 CloudFront는 사용할 수 없지만 자체 CloudFront 배포를 생성하여 캐싱 및 배포 전략을 제어할 수는 있음
	- 프라이빗(private) API Gateway 엔드포인트는 인터페이스 VPC 엔드 포인트(ENI)를 통해 VPC 내부에만 액세스할 수 있음
	- 프라이빗 모드에서는 API Gateway에 대한 액세스를 정의하는 리소스 정책이 필요
	- ACM은 엣지 최적화 및 리전 엔드포인트에 적합
	- ACM을 API Gateway와 통합하려면 우선 API Gateway에 사용자 지정 도메인 이름이라는 리소스를 생성하고, 구성해야 함
	- 엣지 최적화 엔드 포인트는 요청이 CloudFront에서 라우팅되고 TLS 인증서가 CloudFront 배포에 연결되기 때문에 TLS 인증서가 반드시 CloudFront와 같은 리전인 us-east-1에 생성되어야 함
	- API Gateway가 한 리전에 있고, CloudFront를 통해 배포되는 모든 것과 ACM 인증서는 반드시 us-east-1 리전에 있어야 함
	- CloudFront가 us-east-1 리전에 있어 CloudFront를 위한 인증서는 전부 us-east-1에 있음
	- Route 53에 CNAME이나 별칭(A-Alias) 레코드를 설정하면 됨
- 리전 엔드 포인트는 API Gateway와 리전이 같은 클라이언트를 위한 엔드포인트로 API Gateway만 있으므로 TLS 인증서를 API Gateway에 가져올 때는 같은 리전에 속해 있어야 함
- Route 53에서 CNAME이나 별칭 레코드가 여러분의 DNS를 가리키도록 설정하면 됨

### 웹 애플리케이션 방화벽
- AWS 웹 애플리케이션 방화벽(WAF)은 AWS WAF는 계층 7에서 일어나는 일반적인 웹 취약점 공격으로부터 웹 애플리케이션을 보호
- 계층 7은 HTTP이니 HTTP 취약점 공격을 막아주는 것
- 계층 4는 TCP/UDP 프로토콜이고, 웹 애플리케이션 방화벽(WAF)의 배포는 애플리케이션 로드 밸런서, API Gateway CloudFront, AppSync GraphQL API Cognito 사용자 풀에 할 수 있음 -> 중요
- 예를 들어 WAF를 NLB에 배포한다 -> 틀린 것
- 웹 액세스 제어 목록(ACL)과 규칙을 정의해야 함
- 규칙이란 IP 주소를 기반으로 필터링하는 등의 규칙
- IP 세트를 정의할 수 있으며 각 IP 세트는 최대 10,000개의 IP 주소를 가질 수 있음
- 더 많은 IP 주소가 필요하면 규칙을 여러 개 두면 됨
- HTTP 헤더와 본문에 기반해 필터링할 수도 있고, URI 문자열을 조건으로 두어 SQL 주입, 크로스 사이트 스크립팅(XSS) 등의 일반적인 공격을 차단할 수도 있음
- 용량에 제약을 걸어 요청이 최대 2MB를 넘지 않게 하거나 지역 일치(Geo-match) 조건을 두어 특정 국가를 허용 또는 차단할 수도 있음
- 속도 기반 규칙을 설정하면 IP당 요청 수를 측정하여 디도스 공격을 막을 수도 있음
- 특정 IP에서 초당 11개 이상의 요청을 보내지 못하게 한다든지
- 웹 ACL은 리전에만 적용되며 CloudFront는 글로벌로 정의됨
- 규칙 그룹이라는 게 있는데 여러 웹 ACL에 추가할 수 있는 재사용 가능한 규칙 모음
- WAF가 유용한 사용 사례
	- 애플리케이션에 고정 IP를 사용하면서 로드 밸런서와 함께 WAF를 사용하고 싶다고 가정
	- WAF는 네트워크 로드 밸런서(NLB)를 지원하지 않음
	- NLB는 L4에서 WAF는 L7에서만 작동하기 때문
	- WAF를 제공하려면 애플리케이션 로드 밸런서가 있어야 함
	- 애플리케이션 로드 밸런서는 고정 IP가 없음
	- AWS Global Accelerator로 고정 IP를 할당받은 다음 ALB에서 WAF를 활성화하면 해결할 수 있음
	- ALB와 EC2 인스턴스가 있는 리전이 하나 있고,  Global Accelerator를 ALB 앞에 두고, 애플리케이션에서 사용할 고정 IP를 얻음
	- 웹 애플리케이션 방화벽과 웹 ACL을 연결하는데 역시 애플리케이션 로드 밸런서와 동일한 리전에 배치하면  됨

### 실드 - DDoS 보호
- AWS Shield는 디도스 공격으로부터 스스로를 보호하기 위한 서비스
- 디도스란 분산 서비스 거부 공격이라는 뜻으로 인프라에 동시에 엄청난 양의 요청이 세계 곳곳의 여러 컴퓨터에서 유입되는 공격
- 목적은 인프라에 과부하를 일으키는 것으로 실제 사용자들에게 서비스를 제공할 수 없게 만듬
- 분산 서비스 거부가 일어나는 것
- 디도스 공격을 방어하려면 AWS Shield 스탠다드 서비스를 이용하면 되는데 이 서비스는 모든 AWS 고객에게 무료로 활성화되어 있는 서비스로 SYN/UDP Floods나 반사 공격 및 L3/L4 공격으로부터 고객을 보호
- 고급 보호가 필요한 고객을 위한 AWS Shield 어드밴스드 서비스도 있는데 어드밴스드는 선택적으로 제공되는 디도스 완화 서비스로 조직당 월 3,000달러를 지불
- 어드밴스드에서는 더욱 정교한 디도스 공격을 막아주며 Amazon EC2, ELB Amazon CloudFront, AWS Global Accelerator 그리고 Route 53를 보호
- AWS 디도스 대응 팀이 항시 대기하고 있어 공격을 받았을 때 지원을 받을 수 있음
- Shield 어드밴스드는 자동 애플리케이션 계층 디도스 완화도 제공하여 자동으로 WAF 규칙을 생성, 평가, 배포함으로써 L7 공격을 완화할 수 있음
- 웹 애플리케이션 방화벽이 L7에서 일어나는 디도스 공격을 완화하는 규칙을 자동으로 갖게 된다는 뜻
### Firewall Manager
- AWS Firewall Manager은 AWS Organizations에 있는 모든 계정의 방화벽 규칙을 관리하는 서비스
- 여러 계정의 규칙을 동시에 관리할 수 있음
- 보안 규칙의 집합인 보안 정책을 설정할 수 있는데 여기에는 ALB, API Gateway CloudFront 등에 적용되는 웹 애플리케이션 방화벽(WAF) 규칙이나 ALB, CLB, NLB, 엘라스틱 IP CloudFront를 위한 AWS Shield 어드밴스드 규칙 등이 포함
- EC2, 애플리케이션 로드 밸런서 VPC의 ENI 리소스를 위한 보안 그룹을 표준화하는 보안 정책과 VPC 수준의 AWS Network Firewall도 해당됨
- Amazon Route 53 Resolver DNS Firewall도 포함
- AWS Firewall Manager는 이와 같은 모든 방화벽을 한 곳에서 관리할 수 있도록 지원
- 정책은 리전 수준에서 생성되며 조직에 등록된 모든 계정에 적용
- 조직에서 애플리케이션 로드 밸런서에 대한 WAF 규칙을 생성한 다음 새 애플리케이션 로드 밸런서를 생성하는 경우 AWS Firewall Manager에서 자동으로 새 ALB에도 같은 규칙을 적용함
- WAF, Firewall Manager, Shield에는 어떤 차이가 있을까? 
	- WAF, Shield Firewall Manager는 모두 포괄적인 계정 보호를 위한 서비스
	- WAF에서는 웹 ACL 규칙을 정의하는데 리소스별 보호를 구성하는 데에는 WAF가 적절해야 함
	- 여러 계정에서 WAF를 사용하고, WAF 구성을 가속하고 새 리소스 보호를 자동화하려면 Firewall Manager로 WAF 규칙을 관리하면 됨
	- Firewall Manager는 이러한 규칙들을 모든 계정과 모든 리소스에 자동으로 적용
	- Shield 어드밴스드는 디도스 공격으로부터 고객을 보호하고, WAF의 기능 외에도 더 많은 기능을 제공
	- 예를 들어 Shield 대응 팀 지원 고급 보고서 제공, WAF 규칙 자동 생성 등의 기능을 추가로 이용할 수 있음
	- 디도스 공격을 자주 받는다면 Shield 어드밴스드를 사용하는 것도 좋은 선택지가 될 수 있음
	- Firewall Manager는 모든 계정에 Shield 어드밴스드를 배포에도 유용

### DDoS Protection Best Practices
- EC2 인스턴스로 구성된 오토 스케일링 그룹이 있고, 엘라스틱 로드 밸런서가 앞에 위치한다고 가정
- 이때 로드 밸런서를 Global Accelerator를 통하여 고정 IP로 노출하거나 CloudFront를 앞에 둘 수도 있음
- CloudFront는 웹 애플리케이션 방화벽인 WAF 등과 연결할 수 있음
- DNS 라우팅에는 Route 53를 사용할 수 있음
- 마지막으로 또 다른 아키텍처로 CloudFront와 API Gateway가 있음
- CloudFront는 엣지 로케이션에서 사용
- 엣지 로케이션 완화
- 웹 애플리케이션 전송도 엣지에서 일어난다는 뜻
- SYN Flood나 UDP 반사 공격과 같은 DDoS 일반 공격은 Shield 설정으로 막을 수 있음
- Global Accelerator를 사용하면 전 세계에서 엣지를 통해 애플리케이션에 액세스할 수 있음
- Global Accelerator는 Shield와 완전히 통합되어 CloudFront가 백엔드와 호환되지 않는 경우 DDoS 공격 방어에 유용하게 쓰임
- Global Accelerator를 앞에 두는데 어떤 백엔드를 사용하든 CloudFront나 Global Accelerator로 AWS 엣지에 완전 분산이 가능하며 엣지 로케이션을 DDoS 공격으로부터 보호할 수 있음
- Route 53를 사용하는 경우 엣지에 도메인 이름 변환을 글로벌로 설정
- DNS에도 DDoS 보호 메커니즘을 적용할 수 있음
- 엣지에 대한 DDoS 보호를 더 확실히 할 수 있음
- DDoS 완화 모범 사례
	- 인프라 계층 방어는 BP1, BP3와 BP6에 해당하는데 CloudFront, Global Accelerator Route 53, 엘라스틱 로드 밸런싱은 높은 트래픽으로부터 Amazon EC2 인스턴스를 보호
	- 이 서비스들을 사용하면 EC2 인스턴스에 도달하기도 전에 트래픽을 관리할 수 있음
	- EC2 인스턴스에서 오토 스케일링 기능을 활성화하면 오토 스케일링 그룹에 트래픽이 도달한다고 해도 자동으로 확장하여 애플리케이션에서 더 큰 로드를 수용할 수 있음
	- 엘라스틱 로드 밸런싱을 사용하는 경우에는 ELB가 여러 EC2 인스턴스 간 트래픽을 자동으로 분산
	- EC2 인스턴스에 관리 가능한 양의 트래픽이 들어오면서 오토 스케일링 그룹이 이에 따라 확장하는 데에도 무리가 없음
	- 애플리케이션 계층 방어의 예시로는 BP1과 BP2로 악성 요청을 감지 및 필터링하는 방식이 있음
	- CloudFront는 정적 콘텐츠 전송 시 엣지 로케이션에서 전송함으로써 백엔드를 보호
	- 애플리케이션 로드 밸런서나 CloudFront에 WAF를 사용하여 요청 서명에 따라 요청을 필터링 및 차단할 수 있음
	- 특정 IP나 특정 요청 유형만 차단할 수도 있음
	- WAF 속도 기반 규칙을 사용하면 악성 사용자의 IP를 자동으로 차단할 수 있음
	- WAF에 여러 관리형 규칙을 사용하면 평판에 따라 IP를 차단하거나 익명 IP 등을 차단 가능
	- CloudFront로는 특정 지역을 차단할 수 있음
	- CloudFront와 WAF는 관리형 서비스로 요청을 필터링해 줌
	- 따라서 DDoS 공격으로부터 보호할 수 있음
	- Shield Advanced도 있음
	- 이 서비스를 활성화하면 자동으로 WAF 규칙을 생성하여 계층 7 공격을 완화
	- 애플리케이션 계층 방어에 유용
	- 악성 요청이 들어오지 못하도록 하거나 그 수를 최소화하는 식으로 EC2 인스턴스를 보호할 수 있음
	- 공격 지점은 어떻게 줄일 수 있을까?
		- 애플리케이션에 사용되는 백엔드 AWS 리소스가 숨겨져 있음
		- BP1, BP4, BP6가 등
		- CloudFront, API Gateway 엘라스틱 로드 밸런싱을 사용하면 백엔드 리소스를 숨길 수 있음
		- 공격자는 이 리소스가 Lambda 함수인지 EC2 인스턴스나 ECS 태스크인지 알 수 없음
		- 보안 그룹과 네트워크 ACL 등을 설정하여 특정 IP의 트래픽을 필터링할 수 있음
		- Elastic IP(탄력적 IP)도 AWS Shield Advanced로 보호할 수 있음
		- API 엔드 포인트 자체도 보호할 수 있는데 API Gateway를 사용하면 어떤 백엔드든 숨길 수 있음
		- EC2, Lambda 등 무엇인지 알 수 없도록
		- 엣지 최적화 모드를 사용할 경우 이미 글로벌로 설정되어 있음
		- CloudFront에 리전 모드를 더해 사용한다면 DDoS 보호에 관한 제어 기능이 더 강화됨
		- API Gateway에 WAF를 사용하는 경우 모든 HTTP 요청을 필터링할 수 있음
		- API Gateway를 제대로 설정했다면 버스트 제한과 헤더 필터링을 할 수 있음
		- 사용자에게 API 키 사용을 강제할 수도 있음
		- DDoS 공격으로부터 보호할 수 있음

### Amazon GuardDuty
- GuardDuty를 사용하면 지능형 위협 탐지를 이용해서 AWS 계정을 보호할 수 있음
- GuardDuty에는 머신러닝 알고리즘이 있어서 이상 탐지를 수행, 서드파티 데이터를 사용해서 위험 탐지
- GuardDuty는 여러분의 CloudTrail Event Logs 같은 많은 입력 데이터를 확인해서 비정상적인 API 호출이나 무단 배포를 검색
- 관리 이벤트와 데이터 이벤트를 검색할 것
- 관리 이벤트는 VPC 서브넷 생성 이벤트 등을 검색하게 됨
- S3 데이터 이벤트의 경우엔 GetObject, ListObject, DeleteObject 등을 검색
- VPC Flow Logs의 경우엔 비정상적인 인터넷 트래픽을 검색
- 비정상적인 IP 주소를 검색 해 , DNS 로그의 경우엔 DNS 쿼리 안에서 인코딩된 데이터를 전송하는 EC2 인스턴스를 검색하고, 그건 인스턴스에 문제가 생겼다는 얘기죠, 그리고 옵션 기능이 있어서 EKS 감사 로그나 RDS 및 Aurora 로그인 이벤트, EBS, 람다, S3 데이터 이벤트 등 다른 입력 데이터 소스를 검색할 수 있음
- EventBridge 규칙을 설정해서, 발견된 결과가 있으면 자동으로 알림을 받을 수도 있음
- 규칙은 AWS 람다나 SNS 토픽 같이 EventBridge가 타깃화할 수 있는 모든 걸 타깃화할 수 있음
- GuardDuty는 암호화폐 공격을 방어하기 위한 아주 좋은 도구, 전문적인 탐지 기능이 제공됨
- 모든 입력 데이터를 분석하는 방법을 알고, 암호화폐 공격이 있는지 확인하게 됨
- GuardDuty에는 몇 가지 입력 데이터가 있고, VPC Flow Logs, CloudTrail Logs, DNS Logs 등 모든 게 GuardDuty로 들어가게 되됨
- S3 로그, EBS 볼륨, 람다 네트워크 활동, RDS 및 Aurora 로그인 활동, EKS 감사 로그나 런타임 모니터링 등 활성화할 수 있는 몇 가지 옵션 기능도 있음. 이로부터 GuardDuty는 탐지 결과를 생성할 수 있음
- 탐지가 되면 Amazon EventBridge에서 이벤트가 생성되고 EventBridge로부터 규칙을 이용해서 예를 들면 람다 함수라든지 SNS 알림 전송 같은 자동화를 트리거할 수 있음
### Amazon Inspector
- Amazon Inspector는 몇 군데에서 자동화된 보안 평가를 실행할 수 있는 서비스
- EC2 인스턴스에서, EC2 인스턴스에서 시스템 관리자 에이전트를 활용하면 Amazon Inspector가 해당 EC2 인스턴스의 보안을 평가하기 시작할 것
- 의도되지 않은 네트워크 접근 가능성에 대해 분석하고, 실행 중인 운영 체제에서 알려진 취약점을 분석 -> 연속적으로 수행됨
- Amazon Inspector는 컨테이너 이미지를 Amazon ECR로 푸시할 때 실행
	- 도커 이미지
- 컨테이너 이미지가 Amazon ECR로 푸시되면 Amazon Inspector가 알려진 취약점에 대해 검사함
- Amazon Inspector는 Lambda 함수에 대해서도 사용가능
- Amazon Inspector는 Lambda 함수가 배포될 때 함수 코드 및 패키지 종속성에서 소프트웨어 취약성을 다시 분석 -> 함수가 배포될 때 평가함
- Amazon Inspector가 작업을 완료하면 결과를 AWS 보안 허브에 보고
- 결과 및 결과 이벤트를 Amazon Event Bridge로 전송
- 인프라에 있는 취약점을 모아서 볼 수 있음
- Event Bridge로 일종의 자동화를 실행할 수 있음
- Amazon Inspector는 무엇을 평가하는 것?
	- Inspector는 실행 중인 EC2 인스턴스, Amazon ECR의 컨테이너 이미지, Lambda 함수에만 사용된다는 점
	- 필요할 때 인프라만 지속적으로 스캔
	- 즉 취약성 데이터베이스, CVE를 살펴봄
	- EC2, ECR, Lambda에서 패키지 취약성 및 EC2에서 네트워크 도달성을 살펴볼 것
	- 만약 CVE 데이터베이스가 업데이트된다면 Amazon Inspector는 자동으로 다시 실행되어 모든 인프라를 한 번 더 확실히 테스트
	- 실행될 때마다, 우선 순위를 정하기 위해 위험 점수가 모든 취약성과 다시 연관됨
### Amazon Macie
- Macie는 완벽히 관리되는 데이터 보안 및 데이터 프라이버시 서비스
- 머신러닝과 패턴 매칭을 이용해서 AWS에 있는 여러분의 민감한 데이터를 발견하고 보호
	- 개인식별정보, 즉 PII 같은 민감정보에 관해 경보를 제공
- S3 버킷에 PII가 있다면 그게 Macie에 의해 분석되고, Macie는 어떤 데이터를 PII로 분류할 수 있는지 알아내고, EventBridge를 통해 발견 결과를 알려줌
- SNS 토픽이나 람다 함수와 통합할 수 있음
- Macie를 사용해서 S3 버킷에 있는 민감정보를 찾아냄
- 원하는 S3 버킷만 지정하면 됨
