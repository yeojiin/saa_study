### Athena
- Athena는 Amazon S3 버킷에 저장된 **데이터 분석**에 사용하는 **서버리스 쿼리 서비스**
- 데이터를 분석하려면 표준 SQL 언어로 파일을 쿼리해야 함
- Athena는 SQL 언어를 사용하는 Presto 엔진에 빌드됨
- 사용자가 S3 버킷에 데이터를 로드하거나 자신의 S3 버킷에 데이터를 로드하면 Athena 서비스를 사용해 이동하지 않고, Amazon S3에서 데이터를 쿼리하고 분석할 수 있음
- Athena는 서버리스로 S3 버킷의 데이터를 바로 분석
- CSV, JSON, ORC, Avro Parquet 등 다양한 형식을 지원
- 스캔된 데이터의 TB당 고정 가격을 지불하면 됨
- 전체 서비스가 서버리스여서 데이터베이스를 프로비저닝 할 필요가 없음
- Athena는 Amazon QuickSight라는 도구와 함께 사용하는 일이 많음
- 보고서와 대시보드를 생성
- QuickSight는 S3 버킷에 연결된 Athena 다음에 배치됨
- Amazon Athena의 사용 사례로는 임시 쿼리 수행이나 비즈니스 인텔리전스 분석 및 보고가 있고, AWS 서비스에서 발생하는 모든 로그를 쿼리하고 분석할 수 있음
	- VPC 흐름 로그, 로드 밸런서 로그 CloudTrail 추적 등
- 서버리스 SQL 엔진을 사용한 Amazon S3 데이터 분석이 나오면 Athena
- Athena 성능도 향상이 가능
	- 비용을 지불할 때 스캔된 데이터의 TB당 가격을 지불하므로 데이터를 적게 스캔할 유형의 데이터를 사용
	- **열 기반 데이터 유형**을 사용하면 필요한 열만 스캔하므로 비용을 절감할 수 있음
	- Amazon Athena에 권장하는 형식은 Apache Parquet과 ORC
	- 파일을 Apache Parquet나 ORC 형식으로 가져오려면 Glue 등을 사용 해야함 
	- Glue는 적재(ETL) 작업으로 CSV와 Parquet 간의 데이터를 변환하는 데 매우 유용
	- 더 적은 데이터를 스캔해야 하므로 데이터를 압축해 더 적게 검색해야 함
	- 특정 열을 항상 쿼리한다면 데이터 세트를 분할하면 됨
		- S3 버킷에 있는 전체 경로를 슬래시로 분할한다는 뜻
		- 각 슬래시에 다른 열 이름을 붙여 열별로 특정 값을 저장
		- Amazon S3에 있는 데이터를 정리하고 분할
- 데이터 분할의 예
	- Parquet 형식의 전송 데이터에 /year=1991을 입력하면 연도별로 분할하면 연도별로 한 개의 폴더가 생성
	- 연도별 다음으로 월별 분할을 위해 /month=1을 입력하고, 일별 분할을 위해 /day=1을 입력하면 Athena에서 쿼리를 실행할 때 특정 연도, 월, 일로 필터링하면 Amazon S3의 정확히 어떤 폴더에서 데이터를 가져와야 하는지 알 수 있어 데이터의 서브셋만 복구하면 됨
- 큰 파일을 사용해서 **오버헤드를 최소화**하면 성능을 향상할 수 있음
	- Amazon S3에 작은 파일이 너무 많으면 Athena는 큰 파일이 있을 때보다 성능이 떨어짐
	- 파일이 클수록 스캔과 검색이 쉬우므로 128MB 이상의 파일을 사용해야 함
- 연합 쿼리
	- Athena는 S3뿐만 아니라 어떤 곳의 데이터도 쿼리할 수 있음
	- 관계형 데이터베이스나 비관계형 데이터베이스, 객체, 사용자 지정 데이터 원본을 쿼리할 수 있음
- AWS나 온프레미스에서 어떻게 사용? -> 데이터 원본 커넥터를 사용
	- 데이터 원본 커넥터는 Lambda 함수로 다른 서비스에서 연합 쿼리를 실행
	- CloudWatch Logs, DynamoDB RDS 등에서 실행하며 매우 강력
	- Athena와 Lambda 함수가 있을 때 데이터 원본 커넥터당 하나의 Lambda 함수를 가지며 Amazon Athena을 통해 ElastiCache, DocumentDB, DynamoDB, Redshift와 Aurora, SQL 서버, MySQL EMR 서비스의 HBase에서 쿼리를 실행할 수 있음
	- Athena에서 바로 Amazon S3뿐만 아니라 모든 온프레미스 데이터베이스를 쿼리할 수 있으며 쿼리를 조인하거나 경쟁할 수도 있음 -> `연합 쿼리`
- 쿼리 결과는 사후 분석을 위해 Amazon S3 버킷에 저장할 수 있음
### Redshift
- Redshift는 PostgreSQL 기술 기반이지만 온라인 트랜잭션 처리(OLTP)에 사용되지는 않음
- 온라인 분석 처리를 의미하는 OLAP(Online Analytical processing) 유형의 데이터베이스이며 분석과 데이터 웨어하우징에 사용
- 다른 어떤 데이터 웨어하우징보다 성능이 10배 이상 좋고, 데이터가 PB 규모로 확장되므로 모든 데이터를 Redshift에 로드하면 Redshift에서 빠르게 분석 가능
- Redshift는 성능 향상이 가능 -> 열(Columnar) 기반 데이터 스토리지를 사용하기 떄문
- 행 기반이 아니라 병렬 쿼리 엔진이 있는 것
- Redshift 클러스터에서 프로비저닝한 인스턴스에 대한 비용만 지불하면 됨
- 쿼리를 수행할 때 SQL 문을 사용할 수 있음
- Amazon Quicksight 같은 BI 도구나 Tableau 같은 도구도 Redshift와 통합할 수 있음
- Redshift와 Athena 비교
	- Redshift는 Amazon S3에서  모든 데이터를 Redshift에 로드해야 할 때 Redshift에 데이터를 로드하고 나면 Redshift의 쿼리가 더 빠르고, 조인과 통합을 훨씬 더 빠르게 할 수 있음
	- Athena에는 없는 인덱스가 있기 때문
	- Redshift는 데이터 웨어하우스가 높은 성능을 발휘하도록 인덱스를 빌드
	- Amazon S3의 임시 쿼리라면 Athena가 좋은 사용 사례가 되지만 쿼리가 많고 복잡하며 조인하거나 집계하는 등 **집중적인 데이터 웨어하우스**라면 Redshift가 더 좋음
- Redshift 클러스터에는 두 노드가 있음
	- 리더 노드는 쿼리를 계획하고 결과를 집계
	- 계산 노드는 실제로 쿼리를 실행하고 결과를 리더 노드에 보냄
- Redshift 클러스터는 노드 크기를 미리 프로비저닝해야 하고, 비용을 절감하려면 예약 인스턴스를 사용
- 리더 노드에 쿼리를 SQL 형식으로 제출하면 백엔드에서 쿼리가 발생
- Redshift의 스냅샷과 재해 복구
- Redshift는 대부분의 클러스터에는 단일 AZ이나, 이제 일부 클러스터 타입에 대해서는 다중 AZ 모드가 가능
	- 다중 AZ 모드가 된다면 재난 복구 전략이 적용되나, 단일 AZ의 경우, Redshift에 재해 복구 전략을 적용하려면 스냅샷을 사용해야 함
- 스냅샷은 클러스터를 위한 point-in-time(지정 시간) 백업으로 Amazon S3 내부에 저장되며 증가함
	- 변경된 사항만 저장되므로 많은 공간을 절약할 수 있음
- 새로운 Redshift 클러스터에 스냅샷을 복원할 수 있으며 스냅샷에는 두 가지 모드가 있음
	- 수동으로 사용하거나 자동화
	- 자동화 시키면 스냅샷이 8시간마다 또는 5GB마다 자동으로 생성되도록 일정을 예약할 수 있고, 자동화된 스냅샷의 보존 기간을 설정 가능
	- 수동 스냅샷을 사용할 경우 직접 스냅샷을 삭제하기 전까지 스냅샷이 유지
- Redshift는 자동이든 수동이든 클러스터의 스냅샷을 다른 AWS 리전에 자동으로 복사하도록 Redshift를 구성하여 재해 복구 전략을 적용할 수 있음
- Redshift에 데이터를 수집하는 방법
	- Amazon Kinesis Data Firehose를 사용하는 방법
		- Firehose가 다양한 소스로부터 데이터를 받아서 Redshift에 보내는 것
		- Amazon S3 버킷에 데이터를 쓰고, 자동으로 Kinesis Data Firehose가 S3 복사 명령을 실행해 Redshift에 데이터가 로드됨
		- 복사 명령은 수동으로도 가능한데 S3에 데이터를 로드하고 Redshift에서 복사 명령을 실행하면 IAM 역할을 사용해 S3 버킷에서 Amazon Redshift 클러스터로 데이터를 복사
			- S3 버킷은 인터넷을 통해 공용이라서 인터넷을 사용할 수 있음
			- 데이터가 인터넷을 통해 다시 Redshift 클러스터로 이동하게 되는데 향상된 VPC 라우팅 없이도 가능
			- 모든 네트워크를 가상 프라이빗 클라우드에 비공개 상태로 유지하고 싶다면 모든 데이터가 VPC로 완전히 이동되도록 향상된 VPC 라우팅을 사용
			- JDBC 드라이버를 사용해 Redshift 클러스터로 데이터를 삽입하는 방법
				- 예를 들어 애플리케이션에 Redshift 클러스터에 써야 하는 EC2 인스턴스가 있을 때 사용
	- 데이터베이스에 한 번에 한 행씩 쓰는 건 비효율적이기 때문에 Amazon Redshift에 큰 배치로 데이터를 쓰는 것이 좋음
- Amazon S3에 있는 데이터를 Redshift를 사용해 분석은 하지만 Redshift에 로드는 하지 않음 -> 더 많은 처리 능력 사용
- Redshift Spectrum을 이용하면 쿼리를 시작할 수 있는 Redshift 클러스터가 이미 있어야 함
- 쿼리를 시작하면 S3에 있는 데이터에 쿼리를 실행할 수천 개의 Redshift Spectrum 노드에 쿼리가 제출
- Redshift 클러스터에 리더 노드와 여러 개의 컴퓨팅 노드가 있을 때 분석할 데이터는 Amazon S3에 있으며 Redshift 클러스터에서 쿼리를 실행할 것
- 쿼리하려는 테이블이 S3에 있으므로 쿼리는 From S3으로 시작해야 함
- 그러면 Spectrum이 자동으로 시작되고 쿼리는 Amazon S3에서 데이터를 읽고 집계하는 수천 개의 Redshift Spectrum 노드에 제출됨
- 제출이 완료되면 결과가 Amazon Redshift 클러스터를 통해 쿼리를 시작한 곳으로 전송됨
- 이 기능을 사용하면 Amazon S3에서 Redshift로 데이터를 로드하지 않아도 되므로 클러스터에서 프로비저닝한 것보다 더 많은 처리 능력을 활용할 수 있음
### 오픈서치(예: ElasticSearch)
- Amazon OpenSearch는 ElasticSearch의 후속작
- DynamoDB에서 데이터베이스의 기본 키나 인덱스만을 이용해서 쿼리를 할 수 있지만 OpenSearch를 사용하면, 이름에서 알 수 있듯이 모든 필드를 검색할 수 있음
	- 부분 매칭이어도 가능
- OpenSearch를 이용해서 애플리케이션에 검색 기능을 제공하는 방식을 아주 널리 사용
- OpenSearch를 다른 데이터베이스를 보완해서 사용
- OpenSearch는 검색에 사용되지만, 이름과는 달리 분석적 쿼리에도 사용 가능
- OpenSearch 클러스터를 프로비저닝하는 데는 두 가지 모드
	- 관리형 클러스터 모드인데 그 경우엔 실제 물리적인 인스턴스가 프로비저닝됨
	- 서버리스 경로를 선택해서 서버리스 클러스터를 가질 수도 있죠, 그 경우엔 스케일링부터 운영까지 모두 AWS에서 관리
- OpenSearch에는 자체 쿼리 언어가 있는데 자체적으로 SQL을 지원하진 않지만 플러그인을 통해서 SQL 호환성을 활성화할 수 있음
	- 예를 들어 Kinesis Data Firehose, AWS IoT, CloudWatch Logs, 커스텀 빌드 앱 등 다양한 곳에서 오는 데이터를 받을 수 있음
- 보안은 Cognito, IAM 등을 통해 제공되고, 주소 암호화와 전송 중 암호화를 사용할 수 있음
- OpenSearch 서비스 이외에 분석도 가능
	- OpenSearch 대시보드라는 걸 이용해서 OpenSearch 데이터를 시각화할 수 있음
- OpenSearch의 흔한 사용 패턴
	- DynamoDB가 있고, 거기에 여러분의 데이터가 담김
	- 사용자들은 데이터를 삽입, 삭제, 업데이트하면 모든 스트림을 DynamoDB Stream에 전송, 그러면 람다 함수가 실시간으로 그 데이터를 Amazon OpenSearch에 삽입
	- 항목 이름으로 부분 검색을 하거나 항목 ID를 찾을 수 있음
	- 항목 ID를 획득하면 DynamoDB를 호출해서 실제로 그 항목을 DynamoDB 테이블에서 받게 됨
	- OpenSearch는 검색 능력을 제공하지만 데이터의 기본 출처는 DynamoDB 테이블
- CloudWatch Logs를 OpenSearch에 주입하는 방법
	- CloudWatch Logs Subscription Filter를 사용해서 데이터를 실시간으로 AWS가 관리하는 람다 함수에 전송
	- 람다 함수는 실시간으로 모든 데이터를 Amazon OpenSearch로 전송, 또는 CloudWatch Logs를 사용하고 이어서 Subscription Filter를 사용 가능
	- 하지만 Kinesis Data. Firehose가 Subscription Filter로부터 읽을 수 있고, 이어서 Data Firehose이기 때문에 근 실시간으로 데이터가 Amazon OpenSearch에 삽입됨
- Kinesis를 사용하는 다른 패턴을 보면 Kinesis Data Streams를 Amazon OpenSearch에 전송하는 데는 두 가지 전략이 있음
	- Kinesis Data Firehose를 사용하는 방법
		- 근 실시간 타입의 서비스
		- 람다 함수를 이용해서 약간의 데이터 변환도 할 수 있으며 데이터를 Amazon OpenSearch로 전송
	- Kinesis Data Streams를 사용
		- 실시간으로 데이터 스트림을 읽는 람다 함수를 만듦
		- 커스텀 코드를 작성해서 람다 함수가 실시간으로 Amazon OpenSearch에 기록
### EMR(Elastic MapReduce)
- EMR은 Elastic MapReduce의 약어로 AWS에서 빅 데이터 작업을 위한 하둡 클러스터 생성에 사용
- 방대의 양의 데이터를 분석하고 처리할 수 있음
- `하둡 클러스터`가 있는 빅 데이터와 관련된 내용이 나오면 Amazon EMR
- 하둡 클러스터는 프로비저닝해야 하며 수백 개의 EC2 인스턴스로 구성될 수 있음
- EMR은 빅 데이터 전문가가 사용하는 여러 도구와 함께 제공되는데 Apache Spark, HBase, Presto Apache Flink는 설정이 어려운데 Amazon EMR이 상기 서비스에 관한 프로비저닝과 구성을 대신 처리
- 전체 클러스터를 자동으로 확장할 수 있고, 스팟 인스턴스와 통합되므로 가격 할인 혜택을 받을 수도 있음
- Amazon EMR의 사용 사례로는 데이터 처리와 기계 학습, 웹 인덱싱 빅 데이터 작업이 있는데 모든 작업은 하둡, Spark, HBase Presto, Flink와 같은 빅 데이터 관련 기술을 사용
- Amazon EMR은 EC2 인스턴스의 클러스터로 구성되며 여러 노드 유형이 있음
- 마스터 노드는 클러스터를 관리하고, 다른 모든 노드의 상태를 조정하며 장기 실행해야 함
- 코어 노드는 태스크를 실행하고 데이터를 저장 -> 장기 실행해야 함
- 마지막 유형은 테스트만 실행하는 태스크 노드
- 대게 스팟 인스턴스를 사용하며 태스크 노드 사용은 선택 사항 -> 구매 옵션에 따라 다름
- 온디맨드 EC2 인스턴스 유형을 사용하면 신뢰할 수 있고 예측 가능한 유형의 워크로드를 얻게 되고 절대 종료되지 않음
- 최소 1년을 사용해야 하는 예약 인스턴스를 사용하는 경우에는 비용을 크게 절약할 수 있으며 가능한 경우에 EMR이 자동으로 예약 인스턴스를 사용
	- 예약 인스턴스는 장기 실행해야 하는 **마스터 노드와 코어 노드에** 적합
- 스팟 인스턴스는 종료될 수 있으므로 신뢰도는 떨어지지만 저렴
	- 스팟 인스턴스는 **태스크 노드에** 활용하는 게 좋음
- EMR에서 배포할 때는 장기 실행 클러스터에서 예약 인스턴스를 사용하거나 임시 클러스터를 사용해 특정 작업을 수행하고, 분석 완료 후에 삭제할 수 있음
### QuickSight
- Amazon QuickSight는 서버리스 머신 러닝 기반 비즈니스 인텔리전스 서비스
- 비즈니스 인텔리전스니까 대화형 대시보드를 생성
- QuickSight는 대시보드를 생성하고 소유한 데이터 소스와 연결할 수 있음
- 시각화할 수 있고 빠르며 오토 스케일링이 가능
- 웹사이트에 임베드할 수 있으며 세션당 비용을 지불
- QuickSight의 사용 사례
	- 비즈니스 분석, 시각화 구현 시각화된 정보를 통한 임시 분석 수행, 데이터를 활용한 비즈니스 인사이트 획득 등
	- RDS, Aurora, Athena, Redshift, S3 등 다양한 데이터 소스에 연결 가능
- SPICE 엔진
	- 인 메모리 연산 엔진이며 Amazon QuickSight로 데이터를 직접 가져올 때 사용되며 Amazon QuickSight가 다른 DB에 연결돼 있을 때는 작동하지 않음
- Amazon QuickSight의 엔터프라이즈 에디션에서는 액세스 권한이 없는 사용자에게 일부 열이 표시되지 않도록 열 수준 보안(CLS)을 설정할 수 있음
- QuickSight는 어떤 서비스와 통합? 
	- AWS의 다양한 데이터 소스와 통합할 수 있음
	- RDS 데이터베이스, Aurora, 데이터 웨어하우징 서비스인 Redshift, S3에서 임시 쿼리를 수행하는 Athena, 데이터를 가져오기 위한 Amazon S3, OpenSearch 및 시계열 데이터를 최적할 수 있는 Timestream과 통합 가능
	- 타사 데이터 소스와 통합할 수도 있는데 QuickSight가 지원하는 서비스형 소프트웨어여야 함
	- 전체 목록은 QuickSight 웹사이트에 있는데 Salesforce와 Jira가 대표적
	- Teradata 같은 타사 데이터베이스와 통합할 수도 있음
	- 내부적으로 JDBC 프로토콜을 사용하는 온프레미스 데이터베이스와 통합할 수도 있음
	- QuickSight로 직접 Excel 파일, CSV 파일, JSON 문서, TSV 파일, 로그 형식의 ELF 및 CLF 등의 데이터 소스를 가져올 수 있음
- Amazon QuickSight로 데이터 소스를 가져온 다음 SPICE 엔진을 활용해 매우 빠르게 인 메모리 연산을 수행할 수 있음
- QuickSight를 Athena나 Redshift와 함께 사용하는 문제가 자주 나옴
- QuickSight에는 세 가지 개념
	- 대시보드, 분석, 사용자
- 스탠다드 버전에서는 사용자를 정의할 수 있고, 그룹은 엔터프라이즈 버전에서만 사용할 수 있음
- QuickSight의 사용자와 그룹은 QuickSight 서비스 전용 -> IAM 사용자와는 다름
	- IAM 사용자는 관리용으로만 사용
- QuickSight 내에서 사용자와 그룹을 정의하고, 대시보드를 생성하면 됨
- 대시보드는 읽기 전용 스냅샷이며 분석 결과를 공유할 수 있음
- 분석의 구성을 저장
- 분석을 위해 설정한 필터 또는 매개변수 제어, 정렬 옵션 등이 저장되어 대시보드에 표시됨
- 분석이 좀 더 충실하며 특정 사용자 또는 그룹과 분석 결과나 대시보드를 공유할 수 있음
- 대시보드부터 게시 후 액세스 권한이 있는 사용자는 기본 데이터를 볼 수도 있음
- QuickSight에서는 분석 및 대시보드를 생성해야 함
- 특정 사용자나 그룹과 공유할 수 있음
### Glue
- Glue는 추출과 변환 로드 서비스를 관리하며 ETL(분석) 서비스
- 분석을 위해 데이터를 준비하고 변환하는 데 매우 유용
- Glue는 완전 서버리스 서비스이며 원하는 모든 작업을 수행
- S3 버킷이나 Amazon RDS 데이터베이스에 있는 데이터를 데이터 웨어하우스인 Redshift에 로드할 경우
	- Glue를 사용해 추출한 다음 일부 데이터를 필터링하거나 열을 추가하는 등 원하는 대로 데이터를 변형할 수 있음
	- 최종 출력 데이터를 Redshift 데이터 웨어하우스에 로드
	- Glue ETL 서비스 내에서 모든 작업이 이뤄짐
- 데이터를 Parquet 형식으로 변환할 경우
	- Parquet은 열 기반의 데이터 형식이므로 Athena 같은 서비스와 함께 사용하면 효과적
	- 예를 들어 S3 버킷에 CSV 형식으로 된 데이터를 삽입한다고 할 때
	- Glue ETL 서비스를 사용해 CSV 파일을 가져와 Glue 서비스 내에서 Parquet 형식으로 변환한 다음 출력 S3 버킷으로 데이터를 보냄
	- Parquet 형식으로 변환하면 Amazon Athena가 파일을 훨씬 더 잘 분석
	- 전체 과정을 자동화할 수도 있음
	- 파일이 S3 버킷에 삽입될 때마다 Lambda 함수로 이벤트 알림을 보내 Glue ETL 작업을 트리거하는 것
	- Lambda 함수 대신 EventBridge를 사용해도 됨
- Glue Data Catalog는 데이터 세트의 카탈로그
- Glue Data Catalog는 Glue 데이터 크롤러를 실행해 Amazon S3, Amazon RDS, Amazon DynamoDB 또는 호환 가능한 온프레미스 JDBC 데이터베이스에 연결
	- Glue 데이터 크롤러는 데이터베이스를 크롤링하고, 데이터베이스의 테이블 열, 데이터 형식 등의 모든 메타 데이터를 Glue 데이터 카탈로그에 기록
	- ETL을 수행하기 위한 Glue 작업에 활용될 모든 데이터베이스, 테이블 메타 데이터를 갖게 됨
- Amazon Athena는 데이터와 스키마를 검색할 때 백그라운드에서 AWS Glue Data Catalog를 활용 -> Amazon Redshift Spectrum과 Amazon EMR도 같음
- Glue Data Catalog 서비스는 다른 여러 AWS 서비스의 중심
- **Glue 작업 북마크**
	- 새 ETL 작업을 실행할 때 이전 데이터의 재처리를 방지
- Glue Elastic Views는 SQL을 사용해 여러 데이터 스토어의 데이터를 결합하고 복제
	- RDS 데이터베이스와 Aurora 데이터베이스, Amazon S3에 걸친 뷰를 생성
- 커스텀 코드를 지원하지 않으며 Glue가 원본 데이터의 변경 사항을 모니터링
- 서버리스 서비스 
- 여러 데이터 스토어에 분산된 구체화된 뷰인  가상 테이블을 생성할 수 있음
- Glue DataBrew는 사전 빌드된 변환을 사용해 데이터를 정리하고 정규화
- Glue Studio는 Glue에서 ETL 작업을 생성, 실행 및 모니터링하는 GUI
- Glue 스트리밍 ETL은 Apache Spark Structured Streaming 위에 빌드되며 ETL 작업을 배치 작업이 아니라 스트리밍 작업으로 실행할 수 있음
- Kinesis Data Streaming Kafka 또는 AWS의 관리형 Kafka인 MSK에서 Glue 스트리밍 ETL을 사용해 데이터를 읽을 수 있음
###  Lake Formation
- AWS Lake Formation은 데이터 레이크 생성을 도움
- 데이터 레이크란 데이터 분석을 위해 모든 데이터를 한곳으로 모아 주는 **중앙 집중식 저장소**
- Lake Formation은 데이터 레이크 생성을 수월하게 해 주는 완전 관리형 서비스
	- Lake Formation을 사용하면 보통 수개월씩 걸리는 작업을 며칠 만에 완료 가능
- Lake Formation은 데이터 레이크에서의 데이터 검색, 정제, 변환 주입을 도움
- 데이터 수집, 정제나 카탈로깅, 복제 같은 복잡한 수작업을 자동화하고, 기계 학습(ML) 변환 기능으로 중복제거를 수행
- 데이터 레이크에서는 정형 데이터와 비정형 데이터 소스를 결합할 수 있으며 블루프린트를 제공
- 내장된 블루프린트는 데이터를 데이터 레이크로 이전(migrate)하는 것을 도와주며 Amazon S3, Amason RDS, 온프레미스에서 실행되는 관계형 데이터베이스, NoSQL 데이터베이스 등에서 지원
- Lake Formation을 설정하는 이유는 모든 데이터를 한곳에서 처리하는 것 외에도 애플리케이션에서 행, 열 수준의 세분화된 액세스 제어를 할 수 있기 때문
	- AWS Lake Formation에 연결된 애플리케이션에서는 세분화된 액세스 제어가 가능
- Lake Formation 작동 방식?
- AWS Glue 위에 빌드되는 계층이긴 하지만 Glue와 직접 상호 작용하지 않음
- Lake Formation은 Amazon S3에 저장되는 데이터 레이크의 생성을 도움
- 데이터 소스로는 Amazon S3 RDS, Aurora, SQL, NoSQL 같은 온프레미스 데이터베이스 등
- Lake Formation의 블루프린트를 통해 데이터를 주입
- Lake Formation에는 소스 크롤러와 ETL 및 데이터 준비 도구 데이터 카탈로깅 도구가 포함 -> Glue의 기본 서비스
- 데이터 레이크의 데이터를 보호하는 보안 설정과 액세스 제어도 포함
- Lake Formation을 활용하는 서비스로는 Athena, Redshift, EMR, Apache Spark 프레임워크 같은 분석 도구 등
- 사용자는 이와 같은 서비스를 통해 Lake Formation 및 데이터 레이크에 연결
- Lake Formation 사용 이유?
	- **중앙화된 권한**
	- 회사가 데이터 분석에 Athena와 QuickSight를 사용할 때 사용자는 허용된 데이터만 볼 수 있어야 하고, 읽기 권한이 있어야 함
		- 데이터 소스는 Amazon S3 RDS, Aurora 등
	- Athena에 보안을 설정하거나 QuickSight에서 사용자 수준의 보안을 설정할 수 있음
	- S3 버킷 정책이나 사용자 정책에 보안 설정을 할 수도 있고 RDS, Aurora도 마찬가지
	- 보안이 너무 많아져 관리가 어려움 -> Lake Formation이 해결
- Lake Formation은 액세스 제어 기능과 열 및 행 수준 보안이 있음
- Lake Formation에 주입된 모든 데이터는 중앙 S3 버킷에 저장되지만 모든 액세스 제어와 행, 열 수준 보안은 Lake Formation 내에서 관리됨
- Lake Formation에 연결하는 서비스는 `읽기 권한`이 있는 데이터만 볼 수 있게 됨
- Athena, QuickSight 등 어떤 도구를 사용하든 Lake Formation에 연결하면 한곳에서 보안을 관리할 수 있음
### Kinesis 데이터분석 - 개요
- Kinesis Data Analytics는 두가지 종류
	- SQL 애플리케이션용 Kinesis Data Analytics
		- 중앙에 위치하여 Kinesis Data Streams와 Kinesis Data Firehose 데이터 소스에서 데이터를 읽음
		- 둘 중 한군데서 데이터를 읽어 온 다음 SQL 문에 적용하여 실시간 분석을 처리
		- Amazon S3 버킷의 데이터를 참조해 참조 데이터를 조인할 수도 있음
		- 실시간 데이터가 풍성
		- 여러 대상에 데이터를 전송
			- Kinesis Data Streams는 Kinesis Data Analytics의 실시간 쿼리로 스트림을 생성
				- Kinesis Data Streams에 보내면 **EC2에서 실행하는 애플리케이션**이나 **AWS Lambda**로 스트리밍하는 데이터를 실시간으로 처리할 수 있음
			- Kinesis Data Firehose로 바로 전송할 수도 있음
				- Amazon S3 Amazon Redshift이나 Amazon OpenSearch 또는 기타 Firehose 대상에 전송됨
		-  Amazon S3로 데이터를 강화할 수 있고, 완전 관리형 서비스이므로 서버를 프로비저닝하지 않음
		- 오토 스케일링이 가능하며 Kinesis Data Analytics에 전송된 데이터만큼 비용을 지불
		- Kinesis Data Streams나 Kinesis Data Firehose에 데이터를 출력할 수 있고, 사용 사례로는 시계열 분석과 실시간 대시보드와 실시간 지표가 있음
	- Apache Flink 용 Kinesis Data Analytics
		- Kinesis Data Analytics에서 Apache Flink를 사용할 수 있음
		- Apache Flink를 사용하면 Java, Scala, SQL로 애플리케이션을 작성하고, 스트리밍 데이터를 처리, 분석할 수 있음
		- Flink는 코드로 작성해야 하는 특별한 애플리케이션
		- Flink 애플리케이션을 Kinesis Data Analytics의 Flink 전용 클러스터에서 백그라운드로 실행할 수 있음
		- Apache Flink을 사용해 두 개의 메인 데이터 소스인 Kinesis Data Streams나 Amazon MSK의 데이터를 읽을 수 있음
		- AWS의 관리형 클러스터에서 Apache Flink 애플리케이션을 실행할 수 있음
		- Apaches Flink는 표준 SQL보다 훨씬 강력하기 때문에 고급 쿼리 능력이나 필요하거나 Kinesis Data Streams나 AWS의 관리형 Kafka인 Amazon MSK 같은 서비스로부터 스트리밍 데이터를 읽는 능력이 필요할 때 Apache Flink용 Kinesis Data Analytics를 사용
		- 컴퓨팅 리소스를 자동 프로비저닝할 수 있고, 병렬 연산과 오토 스케일링을 할 수 있음
		- 체크포인트와 스냅샷으로 구현되는 애플리케이션 백업이 가능하고, Apache Flink 프로그래밍 기능을 사용할 수도 있음
		- **Apache Flink는 Kinesis Data Streams나 Amazon MSK의 데이터는 읽지만 Kinesis Data Firehose의 데이터는 읽지 못함**
	- Kinesis Data Firehose에서 데이터를 읽고 실시간 분석하려면 SQL 애플리케이션용 Kinesis Data Analytics를 사용해야 함
### MSK - Managed Streaming for Apache Kafka
- Apache Kafka용 Amazon 관리형 스트리밍 서비스로 Amazon MSK로 약어
- Kafka는 Amazon Kinesis의 대안
- 두 서비스 모두 데이터를 스트리밍
- MSK는 AWS의 완전 관리형 Kafka 클러스터 서비스로 그때그때 클러스터를 생성, 업데이트, 삭제
- MSK는 클러스터 내 브로커 노드와 Zookeeper 브로커 노드를 생성 및 관리하고, 고가용성을 위해 VPC의 클러스터를 최대 세 개의 다중 AZ 전역에 배포
- 일반 Kafka 장애를 자동 복구하는 기능이 있으며 EBS 볼륨에 데이터를 저장할 수도 있음
- Amazon MSK 서버리스를 사용할 수 있음
	- MSK에서 Apache Kafka를 실행하지만 서버 프로비저닝이나 용량 관리가 필요 없음
	- MSK가 리소스를 자동으로 프로비저닝하고 컴퓨팅과 스토리지를 스케일링
- Apache Kafka는 데이터를 스트리밍하는 방식
	- Kafka 클러스터는 여러 브로커로 구성되고, 데이터를 생산하는 생산자는 Kinesis, IoT, RDS 등의 데이터를 클러스터에 주입
	- Kafka 주제로 데이터를 전송하면 해당 데이터는 다른 브로커로 완전 복제
	- Kafka 주제는 실시간으로 데이터를 스트리밍하고, 소비자는 데이터를 소비하기 위해 주제를 폴링
	- 소비자는 데이터로 원하는 대로 처리하거나 EMR, S3, SageMaker, Kinesis RDS 등의  대상으로 보냄
- Kinesis Data Streams와 Amazon MSK의 차이점
	- Kinesis Data Streams
		- 1MB의 메시지 크기 제한이 있음
		- `샤드`로 데이터를 스트리밍
		- 용량을 확장하려면 샤드 분할을 축소하려면 샤드 병합
		- TLS 전송 중 암호화 기능이 있음
	- Amazon MSK
		- 1MB이 기본값이고, 더 큰 메시지 보존을 위해 10MB로 설정할 수도 있음
		- `파티션`을 이용한 Kafka 주제를 사용
		- 파티션 추가로 주제 확장만 할 수 있음, 파티션 제거는 불가능
		- 평문과 TLS 전송 중 암호화 기능이 있음
- 두 클러스터 모두 저장 데이터 암호화가 가능
- Amazon MSK에서는 원한다면 1년 이상 데이터를 보관할 수도 있음 -> EBS 스토리지 비용을 지불 시
- MSK에 데이터를 생산하려면 Kafka 생산자를 생성해야 함
- MSK의 데이터를 소비하는 방법
	- Apache Flink용 Kinesis Data Analytics를 사용해 Apache Flink 앱을 실행하고, MSK 클러스터의 데이터를 읽어 오거나 AWS Glue로 ETL 작업을 스트리밍해도 됨
	- Glue는 Apache Spark Streaming으로 구동
	- Amazon MSK를 이벤트 소스로 이용하려면 Lambda 함수를 사용할 수 있고, 자체 Kafka 소비자를 생성해 원하는 플랫폼에서 실행할 수도 있음
		- Amazon EC2 인스턴스나 EC2 클러스터, EKS 클러스터에서 사용 가능
### 빅 데이터 수집 파이프라인
- 애플리케이션 수집 파이프라인이 완전히 서버리스이면서 AWS가 100% 관리해 준다면 좋음
- 실시간으로 데이터를 수집하고 데이터를 변형하고 변형된 데이터를 SQL을 통해 요청하며 쿼리를 사용해 생성한 보고서가 S3에 저장된 후 데이터를 데이터 웨어하우스에 등재해 대시보드를 생성하고자 할 경우
	- 대체로 수집이나 회수, 변형,  쿼리 및 분석 과정에서 흔히 발생하는 빅 데이터 문제는 어떻게 처리하면 좋을까?
- 데이터 생산자가 IoT 장치라고 가정 시 Amazon 클라우드 서비스 중 `IoT Core`는 매우 유용
- IoT Core는 장치에서 실시간으로 전송받은 데이터를 Kinesis Data Stream으로 직접 전달
- Kinesis의 데이터 스트림은 빅 데이터가 실시간으로 Kinesis 서비스에 전송되도록 허용하고, Kinesis Data Firehose는 Kinesis와 통신해서 거의 1분마다 Amazon S3 버킷에 데이터를 입력하고 오프로드 함 ->  수집(ingestion) 버킷
- 많은 디바이스로부터 많은 데이터를 실시간으로 받고, S3 버킷에 데이터를 매분 입력해 줄 뿐만 아니라 람다 함수를 이용해 빠른 속도로 데이터를 정리하거나 변형하도록 함
	- 이때 람다 함수는 Kinesis Data Firehose와 직접 연결된 상태
- 데이터 수집 버킷은 어떤 기능을 수행할까?
	- SQS 대기열을 작동할 수 있는데 선택 사항
	- SQS 대기열은 람다 함수를 실행
		- S3 버킷이 Lambda를 직접 작동할 수 있기 때문에 선택 사항인데 어쨌든 SQS 호출이 가능
	- Lambda가 Amazon Athena SQL 쿼리를 실행하면 Athena 쿼리는 수집 버킷에서 데이터를 가져와 SQL 쿼리를 생성하는데 전부 서버리스
		- 서버리스 쿼리 출력값은 보고(reporting) 버킷으로 들어감
			- 보고 버킷은 Amazon S3에 있는 다른 버킷일 수 있음
	- 이 과정에서 데이터를 보고, 정리, 분석
	- QuickSight를 통해 직접 시각화
	- QuickSight는 Amazon S3 버킷으로 데이터를 시각화하거나 Amazon Redshift 같은 데이터 웨어하우스에 데이터를 입력해 분석
		- **Redshift는 서버리스가 아님!**
		- Redshift 데이터 웨어하우스는 QuickSight의 엔드 포인트로 작용
	- 실시간 데이터 수집과 변형, 서버리스 Lambda와 Redshift 활용 데이터 웨어하우스, QiuckSight 활용 시각화
- IoT Core는 여러 IoT 장치에서 데이터 수집을 허용 하고, Kinesis는 실시간 데이터 수집에 적합
- Firehose는 실시간에 가깝게 S3로 데이터를 운반
	- 선택 가능한 최저 간격은 1분
- Lambda는 Firehose를 도와 데이터를 변형하고, 이후 Amazon S3가 SQS, SNS, Lambda에 알림을 실행
- Lambda는 SQS를 구독할 수 있는데 S3를 람다에 연결하기도 가능
- Athena는 서버리스 SQL 서비스로 Athena 결과는 S3에 직접 저장
- 보고 버킷은 분석된 데이터를 보관
- 시각화를 위한 QuickSight 혹은 추가 분석을 위한 Redshift 등의 보고 도구를 사용할 수 있음
